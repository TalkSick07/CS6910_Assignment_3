{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5G63u5-LKnRE"
      },
      "outputs": [],
      "source": [
        "#Necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "from math import log,log1p\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import keras\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Dropout, SimpleRNN\n",
        "from keras.models import Model,load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hG7cIvJPmae",
        "outputId": "fed7bc39-c17b-438a-8a1b-873e16f8820b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 14.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 73.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 63.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install WandB\n",
        "\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "v_4tJKbkYbgy",
        "outputId": "72377d43-d33d-475a-c6dc-b848a71ddd7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "S7ggF07nYf-v",
        "outputId": "5c1c35fb-c113-4e23-d68e-ae0074844b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtalksick\u001b[0m (\u001b[33mnomads\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220514_153927-1so678rv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/1so678rv\" target=\"_blank\">rare-glade-165</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/1so678rv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe817378090>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "wandb.init(project=\"CS6910_DL_Assignment_3\", entity=\"nomads\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjEbWAYhR1QX",
        "outputId": "323e70b4-3b8b-4dcb-a6c2-7d2103c7fe2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-14 15:39:32--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.143.128, 172.217.218.128, 142.251.18.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.143.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   105MB/s    in 15s     \n",
            "\n",
            "2022-05-14 15:39:48 (124 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Loading the dakshina dataset\n",
        "\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8WiLuWlSIut",
        "outputId": "1b8c5a27-ba1d-4fd5-a10f-30edcf50a768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "#Selecting the Hindi language\n",
        "\n",
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Directory for Training,Validation and Testing\n",
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ],
      "metadata": {
        "id": "nS-InJZ7DvAn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7HtWdlGeSNrm"
      },
      "outputs": [],
      "source": [
        "# Reading the raw corpus\n",
        "#returns the native(Hindi) and romanized(English) versions of the words in the corpus\n",
        "\n",
        "import io\n",
        "def raw_corpus(crp):\n",
        "  Eng = []\n",
        "  Hindi= []\n",
        "\n",
        "  with io.open(crp, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      Eng.append(tokens[1])\n",
        "      Hindi.append(tokens[0])\n",
        "      \n",
        "  return Eng, Hindi                                                             \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_src, train_tgt = raw_corpus(train_dir)\n",
        "val_src, val_tgt = raw_corpus(val_dir)\n",
        "test_src, test_tgt = raw_corpus(test_dir)\n",
        "\n",
        "print(\"Training examples: \", len(train_src))\n",
        "print(\"Validation examples: \", len(val_src))\n",
        "print(\"Testing examples: \", len(test_src))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxApIAtkHaMA",
        "outputId": "9335f12e-d7ae-491d-f123-135ac752d817"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples:  44204\n",
            "Validation examples:  4358\n",
            "Testing examples:  4502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AQLaCYVYTiof"
      },
      "outputs": [],
      "source": [
        "#Shuffling the Training and Validation dataset\n",
        "\n",
        "train_arr = np.arange(len(train_src))\n",
        "np.random.shuffle(train_arr)\n",
        "val_arr = np.arange(len(val_src))\n",
        "np.random.shuffle(val_arr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ip_txt_ns = []\n",
        "tgt_txt_ns = []\n",
        "\n",
        "val_ip_txt_ns = []\n",
        "val_tgt_txt_ns = []\n",
        "\n",
        "ip_char = set()\n",
        "tgt_char = set()\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(train_src, train_tgt):\n",
        "\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "\n",
        "    ip_txt_ns.append(txt_ip)\n",
        "    \n",
        "    tgt_txt_ns.append(txt_tgt)\n",
        "\n",
        "    for char in txt_ip:\n",
        "\n",
        "        if char not in ip_char:\n",
        "\n",
        "            ip_char.add(char)\n",
        "\n",
        "    for char in txt_tgt:\n",
        "\n",
        "        if char not in tgt_char:\n",
        "\n",
        "            tgt_char.add(char)\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(val_src, val_tgt):\n",
        "\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "\n",
        "    val_ip_txt_ns.append(txt_ip)\n",
        "\n",
        "    val_tgt_txt_ns.append(txt_tgt)\n",
        "\n",
        "    for char in txt_ip:\n",
        "\n",
        "        if char not in ip_char:\n",
        "\n",
        "            ip_char.add(char)\n",
        "    for char in txt_tgt:\n",
        "\n",
        "        if char not in tgt_char:\n",
        "\n",
        "            tgt_char.add(char)\n",
        "\n"
      ],
      "metadata": {
        "id": "JTCTaFdeJEq3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip_txt= []\n",
        "tgt_txt= []\n",
        "\n",
        "for i in range(len(train_src)):\n",
        "\n",
        "    ip_txt.append(ip_txt_ns[train_arr[i]])\n",
        "\n",
        "    tgt_txt.append(tgt_txt_ns[train_arr[i]])\n",
        "\n",
        "val_ip_txt= []\n",
        "val_tgt_txt= []\n",
        "\n",
        "for i in range(len(val_src)):\n",
        "\n",
        "    val_ip_txt.append(val_ip_txt_ns[val_arr[i]])\n",
        "    \n",
        "    val_tgt_txt.append(val_tgt_txt_ns[val_arr[i]])\n",
        "\n",
        "ip_char.add(\" \")\n",
        "tgt_char.add(\" \")\n",
        "\n",
        "ip_char = sorted(list(ip_char))\n",
        "tgt_char = sorted(list(tgt_char))"
      ],
      "metadata": {
        "id": "d3zorEFeRYLE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_tokens = len(ip_char)\n",
        "dec_tokens = len(tgt_char)\n",
        "\n",
        "max_enc_seq_length = max([len(txt) for txt in ip_txt])\n",
        "max_dec_seq_length = max([len(txt) for txt in tgt_txt])\n",
        "\n",
        "val_max_enc_seq_length = max([len(txt) for txt in val_ip_txt])\n",
        "val_max_dec_seq_length = max([len(txt) for txt in val_tgt_txt])\n",
        "\n",
        "print(\"Number of samples:\", len(ip_txt))\n",
        "print(\"Number of unique input tokens:\", enc_tokens)\n",
        "print(\"Number of unique output tokens:\", dec_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_enc_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_dec_seq_length)\n",
        "print(\"Max sequence length for val inputs:\", val_max_enc_seq_length)\n",
        "print(\"Max sequence length for val outputs:\", val_max_dec_seq_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN_W9Y_JSmB5",
        "outputId": "14989f01-4afe-4337-ed90-35c9441076a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 44204\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 21\n",
            "Max sequence length for val inputs: 18\n",
            "Max sequence length for val outputs: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(ip_char)\n",
        "print(tgt_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRWzkHHpTKCk",
        "outputId": "371eff39-b182-430d-a3e7-f201ca4a8d1e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "[' ', 'B', 'E', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSS8FMPYUknp",
        "outputId": "7940c1f5-ba33-4623-9d97-052f7d9be1b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['asamanya', 'tekne', 'husali', 'mangen', 'smarakon', 'palace', 'gair', 'peel', 'moortipujak', 'naidoo']\n",
            "['Bअसामान्यE', 'BटेकनेE', 'BहुलसीE', 'BमागेंE', 'Bस्मारकोंE', 'BपैलेसE', 'BगैरE', 'BपिलE', 'Bमूर्तिपूजकE', 'BनायडूE']\n"
          ]
        }
      ],
      "source": [
        "print(ip_txt[10:20])\n",
        "print(tgt_txt[10:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sn8Ss3PVkEL",
        "outputId": "fd0071a7-c883-4026-8e4e-1a7915eef141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n"
          ]
        }
      ],
      "source": [
        "ip_idx = dict([(char, i) for i, char in enumerate(ip_char)])\n",
        "tgt_idx = dict([(char, i) for i, char in enumerate(tgt_char)])\n",
        "\n",
        "print(ip_idx)\n",
        "print(tgt_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0LZmzMNnVqcz"
      },
      "outputs": [],
      "source": [
        "enc_ip = np.zeros((len(ip_txt), max_enc_seq_length), dtype=\"float32\")\n",
        "\n",
        "dec_ip = np.zeros((len(ip_txt), max_dec_seq_length), dtype=\"float32\")\n",
        "\n",
        "dec_tgt = np.zeros((len(ip_txt), max_dec_seq_length, dec_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (txt_ip, txt_tgt) in enumerate(zip(ip_txt, tgt_txt)):\n",
        "\n",
        "    for t, char in enumerate(txt_ip):\n",
        "\n",
        "        enc_ip[i, t] = ip_idx[char]\n",
        "\n",
        "    enc_ip[i, t + 1 :] = ip_idx[\" \"]\n",
        "\n",
        "    for t, char in enumerate(txt_tgt):\n",
        "\n",
        "        dec_ip[i, t] = tgt_idx[char]\n",
        "\n",
        "        if t > 0:\n",
        "\n",
        "            dec_tgt[i, t - 1, tgt_idx[char]] = 1.0\n",
        "\n",
        "    dec_ip[i, t + 1: ] = tgt_idx[\" \"]\n",
        "    dec_tgt[i, t:, tgt_idx[\" \"]] = 1.0\n",
        "\n",
        "val_enc_ip = np.zeros((len(ip_txt), val_max_enc_seq_length), dtype=\"float32\")\n",
        "\n",
        "val_dec_ip = np.zeros((len(ip_txt), val_max_dec_seq_length), dtype=\"float32\")\n",
        "\n",
        "val_dec_tgt = np.zeros((len(ip_txt), val_max_dec_seq_length, dec_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (txt_ip, txt_tgt) in enumerate(zip(val_ip_txt, val_tgt_txt)):\n",
        "\n",
        "    for t, char in enumerate(txt_ip):\n",
        "\n",
        "        val_enc_ip[i, t] = ip_idx[char]\n",
        "\n",
        "    val_enc_ip[i, t + 1 :] = ip_idx[\" \"]\n",
        "\n",
        "    for t, char in enumerate(txt_tgt):\n",
        "\n",
        "        val_dec_ip[i, t] = tgt_idx[char]\n",
        "\n",
        "        if t > 0:\n",
        "\n",
        "            val_dec_tgt[i, t - 1, tgt_idx[char]] = 1.0\n",
        "    \n",
        "    val_dec_ip[i, t + 1: ] = tgt_idx[\" \"]\n",
        "    \n",
        "    val_dec_tgt[i, t:, tgt_idx[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90YY_I-JVwcS",
        "outputId": "d146926f-99d0-4f2c-a1c1-fa29c8e830da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: ' ', 1: 'B', 2: 'E', 3: 'ँ', 4: 'ं', 5: 'ः', 6: 'अ', 7: 'आ', 8: 'इ', 9: 'ई', 10: 'उ', 11: 'ऊ', 12: 'ऋ', 13: 'ए', 14: 'ऐ', 15: 'ऑ', 16: 'ओ', 17: 'औ', 18: 'क', 19: 'ख', 20: 'ग', 21: 'घ', 22: 'ङ', 23: 'च', 24: 'छ', 25: 'ज', 26: 'झ', 27: 'ञ', 28: 'ट', 29: 'ठ', 30: 'ड', 31: 'ढ', 32: 'ण', 33: 'त', 34: 'थ', 35: 'द', 36: 'ध', 37: 'न', 38: 'प', 39: 'फ', 40: 'ब', 41: 'भ', 42: 'म', 43: 'य', 44: 'र', 45: 'ल', 46: 'व', 47: 'श', 48: 'ष', 49: 'स', 50: 'ह', 51: '़', 52: 'ा', 53: 'ि', 54: 'ी', 55: 'ु', 56: 'ू', 57: 'ृ', 58: 'ॅ', 59: 'े', 60: 'ै', 61: 'ॉ', 62: 'ो', 63: 'ौ', 64: '्', 65: 'ॐ'}\n"
          ]
        }
      ],
      "source": [
        "rev_ip_char_idx = dict((i, char) for char, i in ip_idx.items())\n",
        "\n",
        "rev_tgt_char_idx = dict((i, char) for char, i in tgt_idx.items())\n",
        "\n",
        "print(rev_tgt_char_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TaKKzUM6Wrbq"
      },
      "outputs": [],
      "source": [
        "x_test = val_enc_ip\n",
        "y_test = val_tgt_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ccqb07SSW_VG"
      },
      "outputs": [],
      "source": [
        "class Seq_to_Seq(object):\n",
        "\n",
        "  def __init__(self,cell = 'RNN',ip_emb = 32,epochs = 10, hidden_layer=32,batch_size = 32, learning_rate= 1e-3, \n",
        "               dropout=0.4,pred ='greedy',beam_width = 5,num_enc = 1,num_dec = 1):\n",
        "    \n",
        "        self.cell = cell\n",
        "        self.ip_emb = ip_emb\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dropout = dropout\n",
        "        self.pred = pred\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.beam_width = beam_width\n",
        "        self.num_enc = num_enc\n",
        "        self.num_dec = num_dec\n",
        "\n",
        "  def fit_model(self,enc_ip,dec_ip,dec_tgt,x_test, y_test):\n",
        "\n",
        "        # Define an input sequence and process it.\n",
        "        enc_ips = Input(shape=(None, ),name = 'Enc_ips')\n",
        "\n",
        "        enc_emb =  Embedding(enc_tokens, self.ip_emb , mask_zero = True,name = 'Enc_emb')(enc_ips)\n",
        "\n",
        "        enc_ops = enc_emb\n",
        "\n",
        "        if self.cell == 'LSTM':\n",
        "\n",
        "            enc_lstm = LSTM(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "\n",
        "            enc_ops, hs, cs = enc_lstm(enc_ops)\n",
        "\n",
        "            enc_states = [hs, cs]\n",
        "\n",
        "            # Add a LSTM layer with hidden_layer internal units.\n",
        "\n",
        "            for i in range( 2, self.num_enc +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "                enc_lstm = LSTM(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "\n",
        "                enc_ops, hs, cs = enc_lstm(enc_ops,initial_state = enc_states)\n",
        "\n",
        "                enc_states = [hs, cs]\n",
        "\n",
        "        elif self.cell == 'GRU':\n",
        "\n",
        "            enc_gru = GRU(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "\n",
        "            enc_ops, hs = enc_gru(enc_ops)\n",
        "\n",
        "            enc_states = [hs]\n",
        "\n",
        "            for i in range(2, self.num_enc +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "                enc_gru = GRU(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "\n",
        "                enc_ops, hs = enc_gru(enc_ops, initial_state = enc_states)\n",
        "\n",
        "                enc_states = [hs]  \n",
        "\n",
        "        elif self.cell == 'RNN':\n",
        "\n",
        "            enc_rnn = SimpleRNN(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "\n",
        "            enc_ops, hs = enc_rnn(enc_ops)\n",
        "\n",
        "            enc_states = [hs]\n",
        "\n",
        "            for i in range(2, self.num_enc +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "                enc_rnn = SimpleRNN(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "\n",
        "                enc_ops, hs = enc_rnn(enc_ops, initial_state = enc_states)\n",
        "\n",
        "                enc_states = [hs]  \n",
        "\n",
        "        # Set up the dec, using `enc_states` as initial state.\n",
        "        dec_ips = Input(shape=(None,), name = 'Dec_ips')\n",
        "\n",
        "        dec_emb_layer = Embedding(dec_tokens, self.hidden_layer, mask_zero = True, name = 'Dec_emb')\n",
        "\n",
        "        dec_emb = dec_emb_layer(dec_ips)\n",
        "\n",
        "        dec_ops = dec_emb\n",
        "\n",
        "        if self.cell == 'LSTM':\n",
        "\n",
        "            dec_lstm = LSTM(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "\n",
        "            dec_ops, _, _ = dec_lstm(dec_ops, initial_state = enc_states)\n",
        "          \n",
        "            for i in range(2, self.num_dec +1):\n",
        "\n",
        "              layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "              dec_lstm = LSTM(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "\n",
        "              dec_ops, _, _ = dec_lstm(dec_ops, initial_state = enc_states)\n",
        "\n",
        "        elif self.cell == 'GRU':\n",
        "            dec_gru = GRU(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "\n",
        "            dec_ops, _ = dec_gru(dec_ops, initial_state = enc_states)\n",
        "\n",
        "            for i in range(2, self.num_dec+1):\n",
        "\n",
        "              layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "              dec_gru = GRU(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "\n",
        "              dec_ops, _ = dec_gru(dec_ops, initial_state = enc_states)\n",
        "\n",
        "        elif self.cell == 'RNN':\n",
        "            dec_rnn = SimpleRNN(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "\n",
        "            dec_ops, _ = dec_rnn(dec_ops, initial_state = enc_states)\n",
        "\n",
        "            for i in range(2, self.num_dec+1):\n",
        "\n",
        "              layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "              dec_rnn = SimpleRNN(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "\n",
        "              dec_ops, _ = dec_rnn(dec_ops, initial_state = enc_states)\n",
        "\n",
        "        dec_dense = Dense(dec_tokens, activation='softmax', name = 'dense')\n",
        "\n",
        "        dec_ops = dec_dense(dec_ops)\n",
        "\n",
        "        # Define the model that takes enc and dec input \n",
        "        # to output dec_ops\n",
        "        model = Model([enc_ips, dec_ips], dec_ops)\n",
        "        model.summary()\n",
        "        \n",
        "        # Define the optimizer\n",
        "        optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "        model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "      \n",
        "        model.fit(\n",
        "            [enc_ip, dec_ip],\n",
        "            dec_tgt,\n",
        "            batch_size=self.batch_size,\n",
        "            epochs=self.epochs,\n",
        "            callbacks = [WandbCallback()]\n",
        "            )\n",
        "        \n",
        "        enc_model,dec_model = self.inference_model(model)\n",
        "    \n",
        "        total = 0\n",
        "        right = 0\n",
        "        for i in range(len(val_src)):\n",
        "          input_seq = x_test[i : i + 1]\n",
        "          result = self.decode_sequence(enc_model,dec_model,input_seq)\n",
        "\n",
        "          target = y_test[i]\n",
        "          target = target[1:len(target)-1]\n",
        "          result = result[0:len(result)-1]\n",
        "\n",
        "          if result.strip() == target.strip():\n",
        "            right = right + 1\n",
        "          \n",
        "          total = total + 1\n",
        "          accuracy_epoch = right/total\n",
        "\n",
        "          if total % 50 == 0:\n",
        "            wandb.log({'epoch_accuracy' : accuracy_epoch})\n",
        "        \n",
        "        val_accuracy = right/total\n",
        "\n",
        "        wandb.log({'val_accuracy' : val_accuracy})\n",
        "    \n",
        "  def inference_model(self,model):\n",
        "        enc_ips = model.input[0]  \n",
        "\n",
        "        if self.cell == 'RNN' or self.cell == 'GRU':\n",
        "\n",
        "          enc_ops, hs_enc = model.get_layer('Enc_hidden_'+ str(self.num_enc)).output\n",
        "\n",
        "          enc_states = [hs_enc]\n",
        "\n",
        "          enc_model = Model(enc_ips, enc_states)\n",
        "\n",
        "          dec_ips = model.input[1]  \n",
        "\n",
        "          dec_ops = model.get_layer('Dec_emb')(dec_ips)\n",
        "\n",
        "          dec_states_ips = []\n",
        "\n",
        "          dec_states = []\n",
        "\n",
        "          for i in range(1,self.num_dec +1):\n",
        "\n",
        "            dec_state_input_h = keras.Input(shape=(self.hidden_layer,))\n",
        "\n",
        "            curr_states_ips = [dec_state_input_h]\n",
        "\n",
        "            dec = model.get_layer('Dec_hidden_'+ str(i))\n",
        "\n",
        "            dec_ops, hs_dec = dec(dec_ops, initial_state=curr_states_ips)\n",
        "\n",
        "            dec_states += [hs_dec]\n",
        "\n",
        "            dec_states_ips += curr_states_ips\n",
        "\n",
        "        elif self.cell == 'LSTM':\n",
        "\n",
        "          enc_ops, hs_enc, cs_enc = model.get_layer('Enc_hidden_'+ str(self.num_enc)).output \n",
        "\n",
        "          enc_states = [hs_enc, cs_enc]\n",
        "\n",
        "          enc_model = Model(enc_ips, enc_states)\n",
        "\n",
        "          dec_ips = model.input[1]  \n",
        "\n",
        "          dec_ops = model.get_layer('Dec_emb')(dec_ips)\n",
        "\n",
        "          dec_states_ips = []\n",
        "\n",
        "          dec_states = []\n",
        "\n",
        "          for i in range(1,self.num_dec +1):\n",
        "            dec_state_input_h = keras.Input(shape=(self.hidden_layer,))\n",
        "\n",
        "            dec_state_input_c = keras.Input(shape=(self.hidden_layer,))\n",
        "\n",
        "            curr_states_ips = [dec_state_input_h, dec_state_input_c]\n",
        "\n",
        "            dec = model.get_layer('Dec_hidden_'+ str(i))\n",
        "\n",
        "            dec_ops, hs_dec, cs_dec = dec(dec_ops, initial_state=curr_states_ips)\n",
        "\n",
        "            dec_states += [hs_dec, cs_dec]\n",
        "\n",
        "            dec_states_ips += curr_states_ips\n",
        "\n",
        "\n",
        "        dec_dense = model.get_layer('dense')\n",
        "\n",
        "        dec_ops = dec_dense(dec_ops)\n",
        "\n",
        "        dec_model = Model([dec_ips] + dec_states_ips, [dec_ops] + dec_states)\n",
        "\n",
        "        return enc_model,dec_model\n",
        "\n",
        "  def decode_sequence(self,enc_model,dec_model,input_seq):\n",
        "\n",
        "        # Encode the input as state vectors.\n",
        "        states_value = [enc_model.predict(input_seq)] * self.num_dec\n",
        "        \n",
        "        # Generate empty target sequence of length 1.\n",
        "        target_seq = np.zeros((1, 1))\n",
        "\n",
        "        # Populate the first character of target sequence with the start character.\n",
        "        target_seq[0, 0] = tgt_idx['B']\n",
        "\n",
        "        # Sampling loop for a batch of sequences\n",
        "        # (to simplify, here we assume a batch of size 1).\n",
        "        stop_condition = False\n",
        "        decoded_sentence = \"\"\n",
        "\n",
        "        while not stop_condition:\n",
        "\n",
        "            if self.cell == 'RNN' or self.cell == 'GRU':\n",
        "\n",
        "              dummy = dec_model.predict([target_seq] + [states_value])\n",
        "\n",
        "              output_tokens, states_value = dummy[0],dummy[1:]\n",
        "              \n",
        "            elif self.cell == 'LSTM':  \n",
        "\n",
        "              dummy = dec_model.predict([target_seq] + states_value)\n",
        "\n",
        "              output_tokens, states_value = dummy[0],dummy[1:]\n",
        "\n",
        "            if self.pred == 'greedy':\n",
        "\n",
        "              beam_w = 1\n",
        "            elif self.pred == 'beam_search':\n",
        "\n",
        "              beam_w = self.beam_width\n",
        "\n",
        "            sampled_token_index = self.beam_search_dec(output_tokens[0,:,:], beam_w)\n",
        "            sampled_token_index = sampled_token_index[beam_w-1][0]\n",
        "\n",
        "            # Sample a token\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "            sampled_char = rev_tgt_char_idx[sampled_token_index]\n",
        "\n",
        "            decoded_sentence += sampled_char\n",
        "\n",
        "            # Exit condition: either hit max length\n",
        "            # or find stop character.\n",
        "            if sampled_char == 'E' or len(decoded_sentence) > max_dec_seq_length:\n",
        "                stop_condition = True\n",
        "\n",
        "            # Update the target sequence (of length 1).\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "\n",
        "        return decoded_sentence\n",
        "  \n",
        "  def beam_search_dec(self,data, k):\n",
        "    \n",
        "        sequences = [[list(), 0.0]]\n",
        "        # walk over each step in sequence\n",
        "        for row in data:\n",
        "          all_candidates = list()\n",
        "          # expand each current candidate\n",
        "          for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "              candidate = [seq + [j], score - log(row[j])]\n",
        "              #candidate = [seq + [j], score - log1p(row[j])]\n",
        "              all_candidates.append(candidate)\n",
        "          # order all candidates by score\n",
        "          ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
        "          # select k best\n",
        "          sequences = ordered[:k]\n",
        "        return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kqROxxYjXId0"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'dropout': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32,64, 128]\n",
        "        },\n",
        "        'ip_emb': {\n",
        "            'values': [32, 64, 128, 256]\n",
        "        },\n",
        "        'num_enc': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'num_dec': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'hidden_layer':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'cell': {\n",
        "            'values': ['RNN', 'GRU', 'LSTM']\n",
        "        },\n",
        "        'dec_search': {\n",
        "            'values': ['beam_search', 'greedy']\n",
        "        },\n",
        "        'beam_width':{\n",
        "            'values': [3,5]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9HlkbRHXM7y",
        "outputId": "883965f4-e3ca-48e8-c4f6-88eafd3c3acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: v2382own\n",
            "Sweep URL: https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/v2382own\n"
          ]
        }
      ],
      "source": [
        "# Initialize a new sweep\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"nomads\", project=\"CS6910_DL_Assignment_3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1JVZmwgmXzuF"
      },
      "outputs": [],
      "source": [
        "def train_sweep():\n",
        "  config_defaults = {\n",
        "        'dropout': 0.4,\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 32,\n",
        "        'epochs' : 10,\n",
        "        'ip_emb': 32,\n",
        "        'num_enc': 2,\n",
        "        'num_dec': 2,\n",
        "        'hidden_layer': 32,\n",
        "        'cell': 'RNN',\n",
        "        'dec_search': 'beam_search',\n",
        "        'beam_width': 5\n",
        "        }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(config = config_defaults)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and ip\n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = str(config.cell)+ '_' + config.dec_search+'_bs_'+str(config.batch_size)\n",
        "  \n",
        "  rnn_model = Seq_to_Seq(config.cell, ip_emb = config.ip_emb, hidden_layer=config.hidden_layer,\n",
        "                learning_rate= config.learning_rate, dropout=config.dropout,pred= config.dec_search,epochs = config.epochs,\n",
        "                batch_size = config.batch_size, beam_width = config.beam_width, num_enc = config.num_enc,num_dec = config.num_dec)\n",
        "  \n",
        "  rnn_model.fit_model(enc_ip,dec_ip,dec_tgt,x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R-mROja-jcTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "edca92707a9c4e0d90d2088f7bd2b372",
            "663230b11588466385f08f0e756d5378",
            "597ab2da290c457d998a4a09cdf9be39",
            "3797a59ed9ca4e66bc80613d6805646d",
            "08c9281db2144d3aa7af8df883db1b36",
            "007b3e59a03643118b89998b70204bc4",
            "6dc616aece36491a9be2eabc8784f345",
            "48356dea09a64a9cb4c5ba7826c1f4ba",
            "b304f250922f4880a5445d2dd7cf8daf",
            "ef626146aee24eefb64e5f0d335e48d3",
            "25a7169c280e45e19e339685955b236f",
            "11b3a1492b9241edbf927c521c0640c2",
            "a7b36e2d07704aa4a1a6e3aeed3fa5ab",
            "b7556830f79d448e9774409273dba45e",
            "c95fa906d1364124b9f4ee085151abeb",
            "9d07df7080b547a9b85652b0d4e230f6"
          ]
        },
        "id": "dBI-NkmXX6Y0",
        "outputId": "abc7bfdd-5d77-4c95-ae24-b821d1b3e6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m55ilzko with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: beam_search\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tip_emb: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220514_154003-m55ilzko</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/m55ilzko\" target=\"_blank\">stellar-sweep-34</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/b6t0jg8m\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/b6t0jg8m</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 128)    3456        ['Enc_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (LSTM)            [(None, None, 128),  131584      ['Enc_emb[0][0]']                \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_1[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_3 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_2[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (LSTM)            [(None, None, 128),  131584      ['Dec_emb[0][0]',                \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_3 (LSTM)            [(None, None, 128),  131584      ['Dec_hidden_2[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 809,922\n",
            "Trainable params: 809,922\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "346/346 [==============================] - 34s 37ms/step - loss: 1.0434 - accuracy: 0.3073 - _timestamp: 1652542849.0000 - _runtime: 46.0000\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - 13s 36ms/step - loss: 0.7235 - accuracy: 0.4876 - _timestamp: 1652542862.0000 - _runtime: 59.0000\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - 13s 39ms/step - loss: 0.5192 - accuracy: 0.6198 - _timestamp: 1652542875.0000 - _runtime: 72.0000\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - 12s 36ms/step - loss: 0.3900 - accuracy: 0.7045 - _timestamp: 1652542888.0000 - _runtime: 85.0000\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - 13s 36ms/step - loss: 0.3153 - accuracy: 0.7564 - _timestamp: 1652542900.0000 - _runtime: 97.0000\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - 12s 35ms/step - loss: 0.2673 - accuracy: 0.7907 - _timestamp: 1652542912.0000 - _runtime: 109.0000\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - 12s 36ms/step - loss: 0.2353 - accuracy: 0.8143 - _timestamp: 1652542925.0000 - _runtime: 122.0000\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - 12s 36ms/step - loss: 0.2117 - accuracy: 0.8313 - _timestamp: 1652542937.0000 - _runtime: 134.0000\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - 12s 36ms/step - loss: 0.1935 - accuracy: 0.8444 - _timestamp: 1652542950.0000 - _runtime: 147.0000\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - 12s 36ms/step - loss: 0.1784 - accuracy: 0.8567 - _timestamp: 1652542962.0000 - _runtime: 159.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edca92707a9c4e0d90d2088f7bd2b372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▆▇▇▇███</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch_accuracy</td><td>▅█▇▄▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85672</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>epoch_accuracy</td><td>0.29862</td></tr><tr><td>loss</td><td>0.17837</td></tr><tr><td>val_accuracy</td><td>0.2983</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">stellar-sweep-34</strong>: <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/m55ilzko\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/m55ilzko</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220514_154003-m55ilzko/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iizjtglf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: greedy\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tip_emb: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220514_161645-iizjtglf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/iizjtglf\" target=\"_blank\">decent-sweep-35</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/b6t0jg8m\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/b6t0jg8m</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 256)    6912        ['Enc_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Dec_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (LSTM)            [(None, None, 128),  197120      ['Enc_emb[0][0]']                \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_1[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (LSTM)            [(None, None, 128),  131584      ['Dec_emb[0][0]',                \n",
            "                                 (None, 128),                     'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_3 (LSTM)            [(None, None, 128),  131584      ['Dec_hidden_2[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 747,330\n",
            "Trainable params: 747,330\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "346/346 [==============================] - 27s 31ms/step - loss: 1.0212 - accuracy: 0.3186 - _timestamp: 1652545044.0000 - _runtime: 38.0000\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - 11s 31ms/step - loss: 0.5657 - accuracy: 0.5864 - _timestamp: 1652545054.0000 - _runtime: 48.0000\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - 11s 30ms/step - loss: 0.3779 - accuracy: 0.7107 - _timestamp: 1652545065.0000 - _runtime: 59.0000\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - 11s 30ms/step - loss: 0.2944 - accuracy: 0.7702 - _timestamp: 1652545075.0000 - _runtime: 69.0000\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - 10s 30ms/step - loss: 0.2479 - accuracy: 0.8042 - _timestamp: 1652545086.0000 - _runtime: 80.0000\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - 11s 30ms/step - loss: 0.2177 - accuracy: 0.8269 - _timestamp: 1652545096.0000 - _runtime: 90.0000\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - 11s 31ms/step - loss: 0.1959 - accuracy: 0.8439 - _timestamp: 1652545107.0000 - _runtime: 101.0000\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - 11s 31ms/step - loss: 0.1786 - accuracy: 0.8570 - _timestamp: 1652545118.0000 - _runtime: 112.0000\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - 11s 31ms/step - loss: 0.1649 - accuracy: 0.8673 - _timestamp: 1652545128.0000 - _runtime: 122.0000\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - 11s 31ms/step - loss: 0.1537 - accuracy: 0.8755 - _timestamp: 1652545139.0000 - _runtime: 133.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b304f250922f4880a5445d2dd7cf8daf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch_accuracy</td><td>▄█▇▄▃▄▂▂▂▁▂▁▂▂▂▁▂▂▂▂▂▁▁▂▁▂▂▂▁▂▂▂▃▂▂▂▂▁▁▁</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.87554</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>epoch_accuracy</td><td>0.31839</td></tr><tr><td>loss</td><td>0.15372</td></tr><tr><td>val_accuracy</td><td>0.31941</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">decent-sweep-35</strong>: <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/iizjtglf\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/iizjtglf</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220514_161645-iizjtglf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1rerm94i with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_search: greedy\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tip_emb: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220514_165227-1rerm94i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/1rerm94i\" target=\"_blank\">still-sweep-36</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/b6t0jg8m\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/b6t0jg8m</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 128)    3456        ['Enc_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (LSTM)            [(None, None, 64),   49408       ['Enc_emb[0][0]']                \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " Dec_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (LSTM)            [(None, None, 64),   33024       ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 64),                      'Enc_hidden_1[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_1[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 64)     4224        ['Dec_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_3 (LSTM)            [(None, None, 64),   33024       ['Enc_hidden_2[0][0]',           \n",
            "                                 (None, 64),                      'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (LSTM)            [(None, None, 64),   33024       ['Dec_emb[0][0]',                \n",
            "                                 (None, 64),                      'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (LSTM)            [(None, None, 64),   33024       ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 64),                      'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_3 (LSTM)            [(None, None, 64),   33024       ['Dec_hidden_2[0][0]',           \n",
            "                                 (None, 64),                      'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 64)]                      'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     4290        ['Dec_hidden_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 226,498\n",
            "Trainable params: 226,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "346/346 [==============================] - 32s 34ms/step - loss: 1.3320 - accuracy: 0.1839 - _timestamp: 1652547189.0000 - _runtime: 42.0000\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - 12s 33ms/step - loss: 1.1566 - accuracy: 0.2337 - _timestamp: 1652547200.0000 - _runtime: 53.0000\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 1.1258 - accuracy: 0.2514 - _timestamp: 1652547212.0000 - _runtime: 65.0000\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 1.0854 - accuracy: 0.2872 - _timestamp: 1652547223.0000 - _runtime: 76.0000\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 1.0433 - accuracy: 0.3212 - _timestamp: 1652547235.0000 - _runtime: 88.0000\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 1.0084 - accuracy: 0.3415 - _timestamp: 1652547247.0000 - _runtime: 100.0000\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 0.9596 - accuracy: 0.3656 - _timestamp: 1652547258.0000 - _runtime: 111.0000\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 0.9186 - accuracy: 0.3773 - _timestamp: 1652547270.0000 - _runtime: 123.0000\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 0.8885 - accuracy: 0.3892 - _timestamp: 1652547282.0000 - _runtime: 135.0000\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - 12s 34ms/step - loss: 0.8654 - accuracy: 0.4018 - _timestamp: 1652547294.0000 - _runtime: 147.0000\n"
          ]
        }
      ],
      "source": [
        "wandb.agent(\"b6t0jg8m\", entity=\"nomads\",project=\"CS6910_DL_Assignment_3\", function =train_sweep,count=20)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edca92707a9c4e0d90d2088f7bd2b372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_663230b11588466385f08f0e756d5378",
              "IPY_MODEL_597ab2da290c457d998a4a09cdf9be39"
            ],
            "layout": "IPY_MODEL_3797a59ed9ca4e66bc80613d6805646d"
          }
        },
        "663230b11588466385f08f0e756d5378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c9281db2144d3aa7af8df883db1b36",
            "placeholder": "​",
            "style": "IPY_MODEL_007b3e59a03643118b89998b70204bc4",
            "value": "0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "597ab2da290c457d998a4a09cdf9be39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc616aece36491a9be2eabc8784f345",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48356dea09a64a9cb4c5ba7826c1f4ba",
            "value": 1
          }
        },
        "3797a59ed9ca4e66bc80613d6805646d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c9281db2144d3aa7af8df883db1b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007b3e59a03643118b89998b70204bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dc616aece36491a9be2eabc8784f345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48356dea09a64a9cb4c5ba7826c1f4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b304f250922f4880a5445d2dd7cf8daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef626146aee24eefb64e5f0d335e48d3",
              "IPY_MODEL_25a7169c280e45e19e339685955b236f"
            ],
            "layout": "IPY_MODEL_11b3a1492b9241edbf927c521c0640c2"
          }
        },
        "ef626146aee24eefb64e5f0d335e48d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b36e2d07704aa4a1a6e3aeed3fa5ab",
            "placeholder": "​",
            "style": "IPY_MODEL_b7556830f79d448e9774409273dba45e",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "25a7169c280e45e19e339685955b236f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c95fa906d1364124b9f4ee085151abeb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d07df7080b547a9b85652b0d4e230f6",
            "value": 1
          }
        },
        "11b3a1492b9241edbf927c521c0640c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b36e2d07704aa4a1a6e3aeed3fa5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7556830f79d448e9774409273dba45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c95fa906d1364124b9f4ee085151abeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d07df7080b547a9b85652b0d4e230f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}