{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "J9ZhrUeTDsx-"
      },
      "outputs": [],
      "source": [
        "#Necessary Libraries\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array,argmax,array_equal\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import models,Input\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU,Lambda,Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.ticker as ticker\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "from tensorflow.keras.layers import TimeDistributed,RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from matplotlib.font_manager import FontProperties"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio -ffmpeg\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bpBD3kXFNQa",
        "outputId": "c5d30fd8-27aa-4fe7-e8d5-678de6b09e0c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: fmpeg\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import os   \n",
        "from tqdm import tqdm_notebook as tqdm                                          #used for progress bar in loops\n",
        "from PIL import Image\n",
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "L5ywf7whFTU0"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dnebWKpu99",
        "outputId": "01ffa77c-31e3-4716-ce69-7ce50b724103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 14:18:47--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.128, 74.125.197.128, 74.125.135.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar.1’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   252MB/s    in 7.7s    \n",
            "\n",
            "2022-05-15 14:18:55 (249 MB/s) - ‘dakshina_dataset_v1.0.tar.1’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Loading the dakshina dataset\n",
        "\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFMo0XNnqDq_",
        "outputId": "1a1dc3ad-fc1f-43e4-dfdf-46328b816ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "#Selecting the Hindi language\n",
        "\n",
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj7Fk6NkCfla",
        "outputId": "a3111622-2a52-4414-e99c-3194a76fd369"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/nirmala-ui.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqk6gJS0C2fO",
        "outputId": "46510731-2609-4ece-ccc3-4dfd6d99ac02"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/nirmala-ui.zip\n",
            "replace nirmala.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace Nirmala.ttf? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace sharefonts.net.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_font=FontProperties(fname='/content/Nirmala.ttf')"
      ],
      "metadata": {
        "id": "p1-V8gSpykEi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hindi_font"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuHHTjPgAS4L",
        "outputId": "69707899-96a7-4058-f996-503e128cef1e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.font_manager.FontProperties at 0x7fd1bc428250>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "JkG0hgUAqER_"
      },
      "outputs": [],
      "source": [
        "#Directory for Training,Validation and Testing\n",
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "PBzvL2e20Sx-"
      },
      "outputs": [],
      "source": [
        "# Reading the raw corpus\n",
        "#returns the native(Hindi) and romanized(English) versions of the words in the corpus\n",
        "\n",
        "import io\n",
        "def raw_corpus(crp):\n",
        "  Eng = []\n",
        "  Hindi= []\n",
        "  with io.open(crp, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      Eng.append(tokens[1])\n",
        "      Hindi.append(tokens[0])\n",
        "  return Eng, Hindi "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "K-VCpVH93sFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d251955b-61b3-4dc9-e708-36d8c574bb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples:  44204\n",
            "Validation examples:  4358\n",
            "Testing examples:  4502\n"
          ]
        }
      ],
      "source": [
        "train_src, train_tgt = raw_corpus(train_dir)\n",
        "val_src, val_tgt = raw_corpus(val_dir)\n",
        "test_src, test_tgt = raw_corpus(test_dir)\n",
        "\n",
        "print(\"Training examples: \", len(train_src))\n",
        "print(\"Validation examples: \", len(val_src))\n",
        "print(\"Testing examples: \", len(test_src))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BvnPFZvV4yKI"
      },
      "outputs": [],
      "source": [
        "ip_txt_ns = []\n",
        "tgt_txt_ns = []\n",
        "val_ip_txt_ns = []\n",
        "val_tgt_txt_ns = []\n",
        "ip_char = set()\n",
        "tgt_char = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "_u0pkPoq5GSq"
      },
      "outputs": [],
      "source": [
        "for (txt_ip, txt_tgt) in zip(train_src, train_tgt):\n",
        "    # tab : \"start sequence\" character\n",
        "    # \\n  : \"end sequence\" character\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "    ip_txt_ns.append(txt_ip)\n",
        "    tgt_txt_ns.append(txt_tgt)\n",
        "\n",
        "    for char in txt_ip:\n",
        "        if char not in ip_char:\n",
        "            ip_char.add(char)\n",
        "\n",
        "    for char in txt_tgt:\n",
        "        if char not in tgt_char:\n",
        "            tgt_char.add(char)\n",
        "\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(val_src, val_tgt):\n",
        "    # tab : \"start sequence\" character\n",
        "    # \\n  : \"end sequence\" character\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "    val_ip_txt_ns.append(txt_ip)\n",
        "    val_tgt_txt_ns.append(txt_tgt)\n",
        "    for char in txt_ip:\n",
        "        if char not in ip_char:\n",
        "            ip_char.add(char)\n",
        "    for char in txt_tgt:\n",
        "        if char not in tgt_char:\n",
        "            tgt_char.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "YcpWebDU4o6_"
      },
      "outputs": [],
      "source": [
        "#Shuffling the Training and Validation dataset\n",
        "\n",
        "train_arr = np.arange(len(train_src))\n",
        "np.random.shuffle(train_arr)\n",
        "val_arr = np.arange(len(val_src))\n",
        "np.random.shuffle(val_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "SD6j9o7H5U1g"
      },
      "outputs": [],
      "source": [
        "ips_txt = []\n",
        "tgts_txt = []\n",
        "\n",
        "for i in range(len(train_src)):\n",
        "    ips_txt.append(ip_txt_ns[train_arr[i]])\n",
        "    tgts_txt.append(tgt_txt_ns[train_arr[i]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ip_txt = []\n",
        "val_tgt_txt = []\n",
        "\n",
        "for i in range(len(val_src)):\n",
        "    val_ip_txt.append(val_ip_txt_ns[val_arr[i]])\n",
        "    val_tgt_txt.append(val_tgt_txt_ns[val_arr[i]])"
      ],
      "metadata": {
        "id": "5IslLeQE4K80"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "FHadGBBO5oEW"
      },
      "outputs": [],
      "source": [
        "ip_char.add(\" \")\n",
        "tgt_char.add(\" \")\n",
        "ip_char = sorted(list(ip_char))\n",
        "tgt_char = sorted(list(tgt_char))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_tokens = len(ip_char)\n",
        "dec_tokens= len(tgt_char)"
      ],
      "metadata": {
        "id": "iMuAKfUb4W4h"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_enc_seq_length = max([len(txt) for txt in ips_txt])\n",
        "max_dec_seq_length = max([len(txt) for txt in tgts_txt])\n",
        "val_max_enc_seq_length = max([len(txt) for txt in val_ip_txt])\n",
        "val_max_dec_seq_length = max([len(txt) for txt in val_tgt_txt])"
      ],
      "metadata": {
        "id": "-MhTrTZG5Aqr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "OtHaPQPw6VuP"
      },
      "outputs": [],
      "source": [
        "ip_tk_idx= dict([(j, k) for k, j in enumerate(ip_char)])\n",
        "tgt_tk_idx= dict([(j, k) for k, j in enumerate(tgt_char)])\n",
        "rev_src_char_idx = dict((i, char) for char, i in ip_tk_idx.items())\n",
        "rev_tgt_char_idx = dict((i, char) for char, i in tgt_tk_idx.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKb2WqwM6rUS",
        "outputId": "c4a42458-3e97-4227-d896-6f4ef5be93c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n"
          ]
        }
      ],
      "source": [
        "print(ip_tk_idx)\n",
        "print(tgt_tk_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "CtAojV-O6p0G"
      },
      "outputs": [],
      "source": [
        "trc_ip_txt = ips_txt[:44160]\n",
        "trc_tgt_txt = tgts_txt[:44160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "31iEPN2D-UPA"
      },
      "outputs": [],
      "source": [
        "ip_encd = np.zeros(\n",
        "    (len(trc_ip_txt), max_enc_seq_length, enc_tokens), dtype=\"float64\"\n",
        ")\n",
        "tgt_decd = np.zeros(\n",
        "    (len(trc_ip_txt), max_dec_seq_length, dec_tokens), dtype=\"float64\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "fCZN_YHH-ZeJ"
      },
      "outputs": [],
      "source": [
        "for i, (txt_ip, txt_tgt) in enumerate(zip(trc_ip_txt, trc_tgt_txt)):\n",
        "    for m, n in enumerate(txt_ip):\n",
        "        ip_encd[i, m, ip_tk_idx[n]] = 1.0\n",
        "    ip_encd[i, m + 1 :, ip_tk_idx[\" \"]] = 1.0\n",
        "    for m, n in enumerate(txt_tgt):\n",
        "        tgt_decd[i, m, tgt_tk_idx[n]] = 1.0\n",
        "    tgt_decd[i, m + 1 :, tgt_tk_idx[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "KWmlTIC8-dTu"
      },
      "outputs": [],
      "source": [
        "val_ip_encd= np.zeros(\n",
        "    (len(val_ip_txt), max_enc_seq_length, enc_tokens), dtype=\"float64\"\n",
        ")\n",
        "val_tgt_decd = np.zeros(\n",
        "    (len(val_tgt_txt), max_dec_seq_length, dec_tokens), dtype=\"float64\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "KSyas_TA-gj1"
      },
      "outputs": [],
      "source": [
        "for i, (txt_ip, txt_tgt) in enumerate(zip(val_ip_txt, val_tgt_txt)):\n",
        "    \n",
        "    for t, n in enumerate(txt_ip):\n",
        "        val_ip_encd[i, t, ip_tk_idx[n]] = 1.0\n",
        "    val_ip_encd[i, t + 1 :, ip_tk_idx[\" \"]] = 1.0\n",
        "\n",
        "    for t, n in enumerate(txt_tgt):\n",
        "        val_tgt_decd[i, t, tgt_tk_idx[n]] = 1.0\n",
        "    val_tgt_decd[i, t + 1: , tgt_tk_idx[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "N-RyyRhTQ2XC"
      },
      "outputs": [],
      "source": [
        "class Bahdanau(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(Bahdanau, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, value):\n",
        "    \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(value)))\n",
        "    \n",
        "    aw = tf.nn.softmax(score, axis=1)\n",
        "    vc = aw * value\n",
        "    vc = tf.reduce_sum(vc, axis=1)\n",
        "\n",
        "    return vc, aw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "2mfk2-afoCeE"
      },
      "outputs": [],
      "source": [
        "class Seq_to_Seq_with_attention(object):\n",
        "\n",
        "  def __init__(self, cell = 'RNN', hidden_layer=32, learning_rate= 1e-3, drop_out = 0.3,\n",
        "               epochs = 10, batch_size = 32, attention = 'bahdanau'):\n",
        "    \n",
        "    self.cell = cell\n",
        "    self.hidden_layer = hidden_layer\n",
        "    self.learning_rate = learning_rate\n",
        "    self.drop_out = drop_out\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = attention\n",
        "\n",
        "  def fit_model(self, ip_encd, tgt_decd):\n",
        "\n",
        "    ip_encds = Input(shape=(max_enc_seq_length, enc_tokens), name='enc_inputs')\n",
        "\n",
        "    if self.cell == 'LSTM':\n",
        "\n",
        "      enc_lstm = LSTM(self.hidden_layer,return_sequences=True, return_state=True, dropout = self.drop_out, name='enc_lstm')\n",
        "      enc_ops, enc_hs, enc_cs = enc_lstm(ip_encds)\n",
        "      states_enc = [enc_hs, enc_cs]\n",
        "\n",
        "    elif self.cell == 'RNN':\n",
        "\n",
        "      enc_rnn = SimpleRNN(self.hidden_layer,return_sequences=True, return_state=True, dropout = self.drop_out, name='enc_rnn')\n",
        "      enc_ops, enc_hs = enc_rnn(ip_encds)\n",
        "      states_enc = [enc_hs]\n",
        "\n",
        "    elif self.cell == 'GRU':\n",
        "\n",
        "      enc_gru = GRU(self.hidden_layer,return_sequences=True, return_state=True, dropout = self.drop_out, name='enc_gru')\n",
        "      enc_ops, enc_hs = enc_gru(ip_encds)\n",
        "      states_enc = [enc_hs]\n",
        "\n",
        "    \n",
        "\n",
        "    # Attention Layer\n",
        "    if self.attention == 'bahdanau':\n",
        "      attention= Bahdanau(self.hidden_layer)\n",
        "\n",
        "    # dec Layers\n",
        "    inps_deco = Input(shape=(1, (dec_tokens + self.hidden_layer)),name='dec_inputs')\n",
        "\n",
        "    if self.cell == 'LSTM':\n",
        "\n",
        "      dec_lstm = LSTM(self.hidden_layer, dropout = self.drop_out, return_state=True, name='dec_lstm')\n",
        "    \n",
        "    elif self.cell == 'GRU':\n",
        "\n",
        "      dec_gru = GRU(self.hidden_layer, dropout = self.drop_out, return_state=True, name='dec_gru')\n",
        "    \n",
        "    elif self.cell == 'RNN':\n",
        "\n",
        "      dec_rnn = SimpleRNN(self.hidden_layer, dropout = self.drop_out, return_state=True, name='dec_rnn')  \n",
        "    \n",
        "    \n",
        "    dec_dense = Dense(dec_tokens, activation='softmax',  name='dec_dense')\n",
        "    all_ops = []\n",
        "\n",
        "    ips = np.zeros((self.batch_size, 1, dec_tokens))\n",
        "    ips[:, 0, 0] = 1 \n",
        "\n",
        "    dec_ops = enc_hs\n",
        "    states = states_enc\n",
        "\n",
        "    for _ in range(max_dec_seq_length):\n",
        "\n",
        "      vc, aw = attention(dec_ops, enc_ops)\n",
        "      vc = tf.expand_dims(vc, 1)\n",
        "      \n",
        "      ips = tf.concat([vc, ips], axis=-1)\n",
        "\n",
        "      if self.cell == 'LSTM':\n",
        "\n",
        "        dec_ops, hs, cs = dec_lstm(ips, initial_state=states)\n",
        "\n",
        "      if self.cell == 'GRU':\n",
        "\n",
        "        dec_ops, hs = dec_gru(ips, initial_state=states)\n",
        "\n",
        "      if self.cell == 'RNN':\n",
        "\n",
        "        dec_ops, hs = dec_rnn(ips, initial_state=states)\n",
        "      \n",
        "      ops = dec_dense(dec_ops)\n",
        "      ops = tf.expand_dims(ops, 1)\n",
        "      all_ops.append(ops)\n",
        "      ips = ops\n",
        "      if self.cell == 'LSTM':\n",
        "\n",
        "        states = [hs, cs]\n",
        "\n",
        "      if self.cell == 'GRU' or self.cell == 'RNN':\n",
        "        \n",
        "        states = [hs]\n",
        "\n",
        "\n",
        "    dec_ops = Lambda(lambda x: K.concatenate(x, axis=1))(all_ops)\n",
        "    model = Model(ip_encds, dec_ops, name='model_enc_dec')\n",
        "    \n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(ip_encd, tgt_decd,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.epochs,\n",
        "              #callbacks = [WandbCallback()]\n",
        "              )\n",
        "    \n",
        "    if self.cell == 'LSTM':\n",
        "      return enc_lstm,attention,dec_lstm,dec_dense\n",
        "    if self.cell == 'GRU':\n",
        "      return enc_gru,attention,dec_gru,dec_dense\n",
        "    if self.cell == 'RNN':\n",
        "      return enc_rnn,attention,dec_rnn,dec_dense  \n",
        "\n",
        "  def evaluate(self,seq_in):\n",
        "    attention_plot = np.zeros((max_dec_seq_length, max_enc_seq_length))\n",
        "\n",
        "    sequence = seq_in\n",
        "\n",
        "    enc_inputs=array(sequence).reshape(1,max_enc_seq_length,enc_tokens)\n",
        "    \n",
        "    enc_inputs = tf.convert_to_tensor(enc_inputs,dtype=tf.float32)\n",
        "    \n",
        "    if self.cell == 'LSTM':\n",
        "      \n",
        "      enc_outputs, enc_state_h, enc_state_c = encoder(enc_inputs)\n",
        "      enc_states = [enc_state_h, enc_state_c]\n",
        "    elif self.cell == 'GRU':\n",
        "      enc_outputs, enc_state_h = encoder(enc_inputs)\n",
        "      enc_states = [enc_state_h]\n",
        "\n",
        "    elif self.cell == 'RNN':\n",
        "      \n",
        "      enc_outputs, enc_state_h = encoder(enc_inputs)\n",
        "      enc_states = [enc_state_h]\n",
        "\n",
        "    all_outputs = []\n",
        "\n",
        "    dec_input_data = np.zeros((1, 1, dec_tokens))\n",
        "    dec_input_data[:, 0, 0] = 1 \n",
        "\n",
        "    inputs = dec_input_data\n",
        "    dec_outputs = enc_state_h\n",
        "    states = enc_states\n",
        "\n",
        "    weigh_atten =[]\n",
        "    for t in range(max_dec_seq_length):\n",
        "\n",
        "      # pay attention\n",
        "      context_vector, attention_weights=attention(dec_outputs, enc_outputs)\n",
        "\n",
        "      # storing the attention weights to plot later on\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      weigh_atten.append(attention_weights)\n",
        "      \n",
        "      attention_plot[t] = attention_weights.numpy()\n",
        "      \n",
        "      dec_outputs=tf.expand_dims(dec_outputs, 1)\n",
        "\n",
        "      context_vector = tf.expand_dims(context_vector, 1)\n",
        "      inputs = tf.concat([context_vector, inputs], axis=-1)\n",
        "\n",
        "      if self.cell == 'LSTM':\n",
        "        dec_outputs, state_h, state_c = decoder(inputs, initial_state=states)\n",
        "      if self.cell == 'GRU':\n",
        "        dec_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "      if self.cell == 'RNN':\n",
        "        dec_outputs, state_h = decoder(inputs, initial_state=states)\n",
        "            \n",
        "      outputs = decoder_dense(dec_outputs)\n",
        "      # Store the current prediction (we will concatenate all predictions later)\n",
        "      outputs = tf.expand_dims(outputs, 1)\n",
        "      all_outputs.append(outputs)\n",
        "      inputs = outputs\n",
        "      if self.cell == 'LSTM':\n",
        "        states = [state_h, state_c]\n",
        "      if self.cell == 'GRU' or self.cell == 'RNN':\n",
        "        states = [state_h]\n",
        "    \n",
        "    dec_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "    seq_outs = dec_outputs[0]\n",
        "    seq_out = tf.argmax(seq_outs, axis=1)\n",
        "    seq_out = seq_out.numpy()\n",
        "    seq_in = tf.argmax(seq_in, axis = 1)\n",
        "    seq_in = seq_in.numpy()\n",
        "    list(filter(lambda num: num != 0, seq_in))\n",
        "    list(filter(lambda num: num != 0, seq_out))\n",
        "    \n",
        "    return seq_in, seq_out, attention_plot, weigh_atten\n",
        "\n",
        "  def plot_attention(self,attention, sequence, predicted_sequence):\n",
        "    \n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 60}\n",
        "    seq = ''\n",
        "    for i in range(len(sequence)):\n",
        "      seq = seq + rev_src_char_idx[sequence[i]]\n",
        "    \n",
        "    pred = ''\n",
        "    for i in range(len(predicted_sequence)):\n",
        "      pred = pred + rev_tgt_char_idx[predicted_sequence[i]]\n",
        "\n",
        "    ax.set_xticklabels(seq, fontdict=fontdict)\n",
        "    ax.set_yticklabels(pred, fontdict=fontdict, fontproperties =hindi_font)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "  def translate(self,seq_in):\n",
        "    seq_in, seq_out, attention_plot, weigh_atten = self.evaluate(seq_in)\n",
        "\n",
        "    a = [0]\n",
        "    for i in range(len(seq_in)):\n",
        "      if seq_in[i] != 0:\n",
        "        a.append(seq_in[i])\n",
        "\n",
        "    b = []\n",
        "    for i in range(len(seq_out)):\n",
        "      if seq_out[i] != 0:\n",
        "        b.append(seq_out[i])\n",
        "  \n",
        "    b = b[:len(b)-1]\n",
        "    print(a)\n",
        "    print(b)\n",
        "    \n",
        "    attention_plot = attention_plot[:len(b), :len(a)]\n",
        "    self.plot_attention(attention_plot, a, b)  \n",
        "\n",
        "    return weigh_atten\n",
        "\n",
        "  def attention_plot(self,val_input):\n",
        "\n",
        "      seq_in = val_input\n",
        "      aw = self.translate(seq_in)  \n",
        "      return aw\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = Seq_to_Seq_with_attention(cell = 'LSTM', hidden_layer=128, learning_rate= 1e-3,\n",
        "                        drop_out=0.2,epochs = 15, batch_size = 128, attention = 'bahdanau')"
      ],
      "metadata": {
        "id": "TjrgRDxe3tEd"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder,attention,decoder,decoder_dense = rnn_model.fit_model(ip_encd,tgt_decd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U2csMA03-dJ",
        "outputId": "547d090f-ed76-44e0-a7df-3e67a8fccb15"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "345/345 [==============================] - 61s 99ms/step - loss: 1.3194 - accuracy: 0.6805\n",
            "Epoch 2/15\n",
            "345/345 [==============================] - 34s 97ms/step - loss: 1.1315 - accuracy: 0.6995\n",
            "Epoch 3/15\n",
            "345/345 [==============================] - 33s 97ms/step - loss: 1.0542 - accuracy: 0.7133\n",
            "Epoch 4/15\n",
            "345/345 [==============================] - 33s 96ms/step - loss: 0.9776 - accuracy: 0.7253\n",
            "Epoch 5/15\n",
            "345/345 [==============================] - 33s 96ms/step - loss: 0.9186 - accuracy: 0.7365\n",
            "Epoch 6/15\n",
            "345/345 [==============================] - 33s 96ms/step - loss: 0.8749 - accuracy: 0.7471\n",
            "Epoch 7/15\n",
            "345/345 [==============================] - 33s 96ms/step - loss: 0.8384 - accuracy: 0.7557\n",
            "Epoch 8/15\n",
            "345/345 [==============================] - 33s 96ms/step - loss: 0.8060 - accuracy: 0.7633\n",
            "Epoch 9/15\n",
            "345/345 [==============================] - 34s 98ms/step - loss: 0.7787 - accuracy: 0.7695\n",
            "Epoch 10/15\n",
            "345/345 [==============================] - 33s 97ms/step - loss: 0.7536 - accuracy: 0.7758\n",
            "Epoch 11/15\n",
            "345/345 [==============================] - 35s 100ms/step - loss: 0.7316 - accuracy: 0.7807\n",
            "Epoch 12/15\n",
            "345/345 [==============================] - 34s 99ms/step - loss: 0.7095 - accuracy: 0.7860\n",
            "Epoch 13/15\n",
            "345/345 [==============================] - 34s 98ms/step - loss: 0.6888 - accuracy: 0.7910\n",
            "Epoch 14/15\n",
            "345/345 [==============================] - 34s 100ms/step - loss: 0.6696 - accuracy: 0.7959\n",
            "Epoch 15/15\n",
            "345/345 [==============================] - 34s 98ms/step - loss: 0.6549 - accuracy: 0.8001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_a = rnn_model.attention_plot(val_ip_encd[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "_wYXWmim4nb5",
        "outputId": "88417191-1a5c-4fcc-f6c2-41860d7df769"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 25, 15, 8, 1, 1, 14]\n",
            "[1, 43, 62, 50, 52, 37]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cstr(s, color='black'):\n",
        "\tif s == ' ':\n",
        "\t\treturn \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "\telse:\n",
        "\t\treturn \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]"
      ],
      "metadata": {
        "id": "yil5VvmdHu_E"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english = [13, 19, 17, 6, 2, 7, 14, 19]\n",
        "hindi = [21, 30, 42, 28, 12, 29, 18, 44]\n",
        "\n",
        "eng_rev = ''\n",
        "for i in range(len(english)):\n",
        "  eng_rev = eng_rev + rev_src_char_idx[english[i]]\n",
        "\n",
        "hindi_rev = ''\n",
        "for i in range(len(hindi)):\n",
        "  hindi_rev = hindi_rev + rev_tgt_char_idx[hindi[i]]\n",
        "\n",
        "print(eng_rev) \n",
        "print(hindi_rev)\n",
        "\n",
        "len_eng = len(english)\n",
        "len_hindi = len(hindi)\n",
        "print(len_eng)\n",
        "print(len_hindi)\n",
        "\n",
        "for i in range(len(hindi)):\n",
        "  print(rev_tgt_char_idx[hindi[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3dbCd2vIvov",
        "outputId": "aba8bdac-a9d6-469b-dbbf-885814ddeb81"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "msqfbgns\n",
            "घडमटऋठकर\n",
            "8\n",
            "8\n",
            "घ\n",
            "ड\n",
            "म\n",
            "ट\n",
            "ऋ\n",
            "ठ\n",
            "क\n",
            "र\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(ov, res,idx):\n",
        "  #print(\"\\nCell Number:\", cell_no, \"\\n\")\n",
        "  tc = []\n",
        "  for i in range(len_eng):\n",
        "    txt = (res[i], get_clr(ov[i]))\n",
        "    tc.append(txt)\n",
        "    if i == len_eng-1:\n",
        "      hf= open(str(idx) + \".html\", \"w\")\n",
        "      hf.write(''.join([cstr(m,color=n) for m,n in tc]))\n",
        "      hf.close()\n",
        "      display(html_print(''.join([cstr(m,color=n) for m,n in tc])))"
      ],
      "metadata": {
        "id": "9NXCu0mQKPMF"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len_hindi):\n",
        "    visualize(w_a[i][:],eng_rev,i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "l2N1BXNkL6nW",
        "outputId": "16f9b93a-d33c-4a15-cfc0-271862689a8a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#a1d0e8#b2d9ec>m </text><text style=color:#000;background-color:#eff7fb>s </text><text style=color:#000;background-color:#c2e1f0>q </text><text style=color:#000;background-color:#89c4e2>f </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#a1d0e8#b2d9ec>m </text><text style=color:#000;background-color:#c2e1f0>s </text><text style=color:#000;background-color:#c2e1f0>q </text><text style=color:#000;background-color:#89c4e2>f </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#89c4e2>s </text><text style=color:#000;background-color:#99cce6>q </text><text style=color:#000;background-color:#f9e8e8>f </text><text style=color:#000;background-color:#99cce6>b </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>q </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#baddee>b </text><text style=color:#000;background-color:#f9d4d4>g </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#85c2e1>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>q </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#c2e1f0>g </text><text style=color:#000;background-color:#f9e8e8>n </text><text style=color:#000;background-color:#89c4e2>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>q </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#c2e1f0>n </text><text style=color:#000;background-color:#c2e1f0>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>q </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#95cae5>n </text><text style=color:#000;background-color:#eff7fb>s </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>q </text><text style=color:#000;background-color:#85c2e1>f </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#95cae5>n </text><text style=color:#000;background-color:#c2e1f0>s </text>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Attention_Memorization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}