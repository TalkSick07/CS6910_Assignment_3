{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing_Seq_to_Seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5G63u5-LKnRE"
      },
      "outputs": [],
      "source": [
        "#Necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "from math import log,log1p\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import csv\n",
        "import keras\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU, Dropout, SimpleRNN\n",
        "from keras.models import Model,load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hG7cIvJPmae",
        "outputId": "de5ab590-a5a5-4723-f89a-ff5acb10ae47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 52.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install WandB\n",
        "\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "v_4tJKbkYbgy",
        "outputId": "78e02944-c0b1-4d29-ff2f-9eaa9d59a36e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "S7ggF07nYf-v",
        "outputId": "ee4dbe62-3140-4746-bb68-a485a6085745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtalksick\u001b[0m (\u001b[33mnomads\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220515_062159-2tlic546</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/2tlic546\" target=\"_blank\">ancient-glade-211</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/2tlic546?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f214ef0e250>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.init(project=\"CS6910_DL_Assignment_3\", entity=\"nomads\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjEbWAYhR1QX",
        "outputId": "5a683411-d714-4cfa-9de3-f8593c0dd34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 06:22:06--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.20.128, 108.177.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   116MB/s    in 14s     \n",
            "\n",
            "2022-05-15 06:22:21 (134 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Loading the dakshina dataset\n",
        "\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8WiLuWlSIut",
        "outputId": "2a693441-d0e1-484b-ab1c-96ee230ba1b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "#Selecting the Hindi language\n",
        "\n",
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Directory for Training,Validation and Testing\n",
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ],
      "metadata": {
        "id": "nS-InJZ7DvAn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7HtWdlGeSNrm"
      },
      "outputs": [],
      "source": [
        "# Reading the raw corpus\n",
        "#returns the native(Hindi) and romanized(English) versions of the words in the corpus\n",
        "\n",
        "import io\n",
        "def raw_corpus(crp):\n",
        "  Eng = []\n",
        "  Hindi= []\n",
        "\n",
        "  with io.open(crp, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      Eng.append(tokens[1])\n",
        "      Hindi.append(tokens[0])\n",
        "      \n",
        "  return Eng, Hindi                                                             \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_src, train_tgt = raw_corpus(train_dir)\n",
        "test_src, test_tgt = raw_corpus(test_dir)\n"
      ],
      "metadata": {
        "id": "OxApIAtkHaMA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AQLaCYVYTiof"
      },
      "outputs": [],
      "source": [
        "#Shuffling the Training and Validation dataset\n",
        "\n",
        "train_arr = np.arange(len(train_src))\n",
        "np.random.shuffle(train_arr)\n",
        "test_arr = np.arange(len(test_src))\n",
        "np.random.shuffle(test_arr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ip_txt_ns = []\n",
        "tgt_txt_ns = []\n",
        "\n",
        "test_ip_txt_ns = []\n",
        "test_tgt_txt_ns = []\n",
        "\n",
        "src_char = set()\n",
        "tgt_char = set()\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(train_src, train_tgt):\n",
        "\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "\n",
        "    ip_txt_ns.append(txt_ip)\n",
        "    \n",
        "    tgt_txt_ns.append(txt_tgt)\n",
        "\n",
        "    for char in txt_ip:\n",
        "\n",
        "        if char not in src_char:\n",
        "\n",
        "            src_char.add(char)\n",
        "\n",
        "    for char in txt_tgt:\n",
        "\n",
        "        if char not in tgt_char:\n",
        "\n",
        "            tgt_char.add(char)\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(test_src, test_tgt):\n",
        "\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "\n",
        "    test_ip_txt_ns.append(txt_ip)\n",
        "\n",
        "    test_tgt_txt_ns.append(txt_tgt)\n",
        "\n",
        "    for char in txt_ip:\n",
        "\n",
        "        if char not in src_char:\n",
        "\n",
        "            src_char.add(char)\n",
        "            \n",
        "    for char in txt_tgt:\n",
        "\n",
        "        if char not in tgt_char:\n",
        "\n",
        "            tgt_char.add(char)\n",
        "\n"
      ],
      "metadata": {
        "id": "JTCTaFdeJEq3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip_txt= []\n",
        "tgt_txt= []\n",
        "\n",
        "for i in range(len(train_src)):\n",
        "\n",
        "    ip_txt.append(ip_txt_ns[train_arr[i]])\n",
        "\n",
        "    tgt_txt.append(tgt_txt_ns[train_arr[i]])\n",
        "\n",
        "test_ip_txt= []\n",
        "test_tgt_txt= []\n",
        "\n",
        "for i in range(len(test_src)):\n",
        "\n",
        "    test_ip_txt.append(test_ip_txt_ns[test_arr[i]])\n",
        "    \n",
        "    test_tgt_txt.append(test_tgt_txt_ns[test_arr[i]])\n",
        "\n",
        "src_char.add(\" \")\n",
        "tgt_char.add(\" \")\n",
        "\n",
        "src_char = sorted(list(src_char))\n",
        "tgt_char = sorted(list(tgt_char))"
      ],
      "metadata": {
        "id": "d3zorEFeRYLE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_tokens = len(src_char)\n",
        "dec_tokens = len(tgt_char)\n",
        "\n",
        "max_enc_seq_length = max([len(txt) for txt in ip_txt])\n",
        "max_dec_seq_length = max([len(txt) for txt in tgt_txt])\n",
        "\n",
        "test_max_enc_seq_length = max([len(txt) for txt in test_ip_txt])\n",
        "test_max_dec_seq_length = max([len(txt) for txt in test_tgt_txt])\n"
      ],
      "metadata": {
        "id": "fN_W9Y_JSmB5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1sn8Ss3PVkEL"
      },
      "outputs": [],
      "source": [
        "src_idx = dict([(char, i) for i, char in enumerate(src_char)])\n",
        "tgt_idx = dict([(char, i) for i, char in enumerate(tgt_char)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0LZmzMNnVqcz"
      },
      "outputs": [],
      "source": [
        "enc_ip = np.zeros((len(ip_txt), max_enc_seq_length), dtype=\"float32\")\n",
        "\n",
        "dec_ip = np.zeros((len(ip_txt), max_dec_seq_length), dtype=\"float32\")\n",
        "\n",
        "dec_tgt = np.zeros((len(ip_txt), max_dec_seq_length, dec_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (txt_ip, txt_tgt) in enumerate(zip(ip_txt, tgt_txt)):\n",
        "\n",
        "    for t, char in enumerate(txt_ip):\n",
        "\n",
        "        enc_ip[i, t] = src_idx[char]\n",
        "\n",
        "    enc_ip[i, t + 1 :] = src_idx[\" \"]\n",
        "\n",
        "    for t, char in enumerate(txt_tgt):\n",
        "\n",
        "        dec_ip[i, t] = tgt_idx[char]\n",
        "\n",
        "        if t > 0:\n",
        "\n",
        "            dec_tgt[i, t - 1, tgt_idx[char]] = 1.0\n",
        "\n",
        "    dec_ip[i, t + 1: ] = tgt_idx[\" \"]\n",
        "    dec_tgt[i, t:, tgt_idx[\" \"]] = 1.0\n",
        "\n",
        "test_enc_ip = np.zeros((len(ip_txt), test_max_enc_seq_length), dtype=\"float32\")\n",
        "\n",
        "test_dec_ip = np.zeros((len(ip_txt), test_max_dec_seq_length), dtype=\"float32\")\n",
        "\n",
        "test_dec_tgt = np.zeros((len(ip_txt), test_max_dec_seq_length, dec_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (txt_ip, txt_tgt) in enumerate(zip(test_ip_txt, test_tgt_txt)):\n",
        "\n",
        "    for t, char in enumerate(txt_ip):\n",
        "\n",
        "        test_enc_ip[i, t] = src_idx[char]\n",
        "\n",
        "    test_enc_ip[i, t + 1 :] = src_idx[\" \"]\n",
        "\n",
        "    for t, char in enumerate(txt_tgt):\n",
        "\n",
        "        test_dec_ip[i, t] = tgt_idx[char]\n",
        "\n",
        "        if t > 0:\n",
        "\n",
        "            test_dec_tgt[i, t - 1, tgt_idx[char]] = 1.0\n",
        "    \n",
        "    test_dec_ip[i, t + 1: ] = tgt_idx[\" \"]\n",
        "    \n",
        "    test_dec_tgt[i, t:, tgt_idx[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "90YY_I-JVwcS"
      },
      "outputs": [],
      "source": [
        "rev_src_char_idx = dict((i, char) for char, i in src_idx.items())\n",
        "\n",
        "rev_tgt_char_idx = dict((i, char) for char, i in tgt_idx.items())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TaKKzUM6Wrbq"
      },
      "outputs": [],
      "source": [
        "x_test = test_enc_ip\n",
        "y_test = test_tgt_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ccqb07SSW_VG"
      },
      "outputs": [],
      "source": [
        "class Seq_to_Seq(object):\n",
        "\n",
        "  def __init__(self,cell = 'RNN',ip_emb = 32,epochs = 10, hidden_layer=32,batch_size = 32, learning_rate= 1e-3, \n",
        "               dropout=0.4,pred ='greedy',beam_width = 5,num_enc = 1,num_dec = 1):\n",
        "    \n",
        "        self.cell = cell\n",
        "        self.ip_emb = ip_emb\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dropout = dropout\n",
        "        self.pred = pred\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.beam_width = beam_width\n",
        "        self.num_enc = num_enc\n",
        "        self.num_dec = num_dec\n",
        "\n",
        "  def fit_model(self,enc_ip,dec_ip,dec_tgt,x_test, y_test):\n",
        "\n",
        "        # Define an input sequence and process it.\n",
        "        enc_ips = Input(shape=(None, ),name = 'Enc_ips')\n",
        "\n",
        "        enc_emb =  Embedding(enc_tokens, self.ip_emb , mask_zero = True,name = 'Enc_emb')(enc_ips)\n",
        "\n",
        "        enc_ops = enc_emb\n",
        "\n",
        "        if self.cell == 'LSTM':\n",
        "\n",
        "            enc_lstm = LSTM(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "\n",
        "            enc_ops, hs, cs = enc_lstm(enc_ops)\n",
        "\n",
        "            enc_states = [hs, cs]\n",
        "\n",
        "            # Add a LSTM layer with hidden_layer internal units.\n",
        "\n",
        "            for i in range( 2, self.num_enc +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "                enc_lstm = LSTM(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "\n",
        "                enc_ops, hs, cs = enc_lstm(enc_ops,initial_state = enc_states)\n",
        "\n",
        "                enc_states = [hs, cs]\n",
        "\n",
        "        elif self.cell == 'GRU':\n",
        "\n",
        "            enc_gru = GRU(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "\n",
        "            enc_ops, hs = enc_gru(enc_ops)\n",
        "\n",
        "            enc_states = [hs]\n",
        "\n",
        "            for i in range(2, self.num_enc +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "                enc_gru = GRU(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "\n",
        "                enc_ops, hs = enc_gru(enc_ops, initial_state = enc_states)\n",
        "\n",
        "                enc_states = [hs]  \n",
        "\n",
        "        elif self.cell == 'RNN':\n",
        "\n",
        "            enc_rnn = SimpleRNN(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=\"Enc_hidden_1\")\n",
        "\n",
        "            enc_ops, hs = enc_rnn(enc_ops)\n",
        "\n",
        "            enc_states = [hs]\n",
        "\n",
        "            for i in range(2, self.num_enc +1):\n",
        "\n",
        "                layer_name = ('Enc_hidden_%d') %i\n",
        "\n",
        "                enc_rnn = SimpleRNN(self.hidden_layer, return_state=True,dropout = self.dropout, return_sequences=True, name=layer_name)\n",
        "\n",
        "                enc_ops, hs = enc_rnn(enc_ops, initial_state = enc_states)\n",
        "\n",
        "                enc_states = [hs]  \n",
        "\n",
        "        # Set up the dec, using `enc_states` as initial state.\n",
        "        dec_ips = Input(shape=(None,), name = 'Dec_ips')\n",
        "\n",
        "        dec_emb_layer = Embedding(dec_tokens, self.hidden_layer, mask_zero = True, name = 'Dec_emb')\n",
        "\n",
        "        dec_emb = dec_emb_layer(dec_ips)\n",
        "\n",
        "        dec_ops = dec_emb\n",
        "\n",
        "        if self.cell == 'LSTM':\n",
        "\n",
        "            dec_lstm = LSTM(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "\n",
        "            dec_ops, _, _ = dec_lstm(dec_ops, initial_state = enc_states)\n",
        "          \n",
        "            for i in range(2, self.num_dec +1):\n",
        "\n",
        "              layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "              dec_lstm = LSTM(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "\n",
        "              dec_ops, _, _ = dec_lstm(dec_ops, initial_state = enc_states)\n",
        "\n",
        "        elif self.cell == 'GRU':\n",
        "            dec_gru = GRU(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "\n",
        "            dec_ops, _ = dec_gru(dec_ops, initial_state = enc_states)\n",
        "\n",
        "            for i in range(2, self.num_dec+1):\n",
        "\n",
        "              layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "              dec_gru = GRU(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "\n",
        "              dec_ops, _ = dec_gru(dec_ops, initial_state = enc_states)\n",
        "\n",
        "        elif self.cell == 'RNN':\n",
        "            dec_rnn = SimpleRNN(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=\"Dec_hidden_1\")\n",
        "\n",
        "            dec_ops, _ = dec_rnn(dec_ops, initial_state = enc_states)\n",
        "\n",
        "            for i in range(2, self.num_dec+1):\n",
        "\n",
        "              layer_name = ('Dec_hidden_%d') %i\n",
        "\n",
        "              dec_rnn = SimpleRNN(self.hidden_layer, return_sequences=True, return_state=True,dropout = self.dropout, name=layer_name)\n",
        "\n",
        "              dec_ops, _ = dec_rnn(dec_ops, initial_state = enc_states)\n",
        "\n",
        "        dec_dense = Dense(dec_tokens, activation='softmax', name = 'dense')\n",
        "\n",
        "        dec_ops = dec_dense(dec_ops)\n",
        "\n",
        "        # Define the model that takes enc and dec input \n",
        "        # to output dec_ops\n",
        "        model = Model([enc_ips, dec_ips], dec_ops)\n",
        "        model.summary()\n",
        "        \n",
        "        # Define the optimizer\n",
        "        optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "        model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "      \n",
        "        model.fit(\n",
        "            [enc_ip, dec_ip],\n",
        "            dec_tgt,\n",
        "            batch_size=self.batch_size,\n",
        "            epochs=self.epochs,\n",
        "            )\n",
        "        \n",
        "        enc_model,dec_model = self.inference_model(model)\n",
        "        dl=['Sno','Input Data','Target data','Predicted Data']\n",
        "    \n",
        "        total = 0\n",
        "        right = 0\n",
        "        for i in range(len(y_test)):\n",
        "          input_seq = x_test[i : i + 1]\n",
        "          result = self.decode_sequence(enc_model,dec_model,input_seq)\n",
        "\n",
        "          target = y_test[i]\n",
        "          target = target[1:len(target)-1]\n",
        "          result = result[0:len(result)-1]\n",
        "          dl1=[i+1,test_ip_txt[i],target,result]\n",
        "          dl.append(dl1)\n",
        "\n",
        "          if result.strip() == target.strip():\n",
        "            right = right + 1\n",
        "          \n",
        "          total = total + 1\n",
        "          accuracy_epoch = right/total\n",
        "        \n",
        "        with open('Vanilla_Predictions.tsv','w',newline='',encoding='utf-8') as file:\n",
        "            writer=csv.writer(file,delimiter='\\t')\n",
        "            writer.writerows(dl)\n",
        "\n",
        "        test_accuracy = right/total\n",
        "        print(test_accuracy)\n",
        "    \n",
        "  def inference_model(self,model):\n",
        "        enc_ips = model.input[0]  \n",
        "\n",
        "        if self.cell == 'RNN' or self.cell == 'GRU':\n",
        "\n",
        "          enc_ops, hs_enc = model.get_layer('Enc_hidden_'+ str(self.num_enc)).output\n",
        "\n",
        "          enc_states = [hs_enc]\n",
        "\n",
        "          enc_model = Model(enc_ips, enc_states)\n",
        "\n",
        "          dec_ips = model.input[1]  \n",
        "\n",
        "          dec_ops = model.get_layer('Dec_emb')(dec_ips)\n",
        "\n",
        "          dec_states_ips = []\n",
        "\n",
        "          dec_states = []\n",
        "\n",
        "          for i in range(1,self.num_dec +1):\n",
        "\n",
        "            dec_state_input_h = keras.Input(shape=(self.hidden_layer,))\n",
        "\n",
        "            curr_states_ips = [dec_state_input_h]\n",
        "\n",
        "            dec = model.get_layer('Dec_hidden_'+ str(i))\n",
        "\n",
        "            dec_ops, hs_dec = dec(dec_ops, initial_state=curr_states_ips)\n",
        "\n",
        "            dec_states += [hs_dec]\n",
        "\n",
        "            dec_states_ips += curr_states_ips\n",
        "\n",
        "        elif self.cell == 'LSTM':\n",
        "\n",
        "          enc_ops, hs_enc, cs_enc = model.get_layer('Enc_hidden_'+ str(self.num_enc)).output \n",
        "\n",
        "          enc_states = [hs_enc, cs_enc]\n",
        "\n",
        "          enc_model = Model(enc_ips, enc_states)\n",
        "\n",
        "          dec_ips = model.input[1]  \n",
        "\n",
        "          dec_ops = model.get_layer('Dec_emb')(dec_ips)\n",
        "\n",
        "          dec_states_ips = []\n",
        "\n",
        "          dec_states = []\n",
        "\n",
        "          for i in range(1,self.num_dec +1):\n",
        "            dec_state_input_h = keras.Input(shape=(self.hidden_layer,))\n",
        "\n",
        "            dec_state_input_c = keras.Input(shape=(self.hidden_layer,))\n",
        "\n",
        "            curr_states_ips = [dec_state_input_h, dec_state_input_c]\n",
        "\n",
        "            dec = model.get_layer('Dec_hidden_'+ str(i))\n",
        "\n",
        "            dec_ops, hs_dec, cs_dec = dec(dec_ops, initial_state=curr_states_ips)\n",
        "\n",
        "            dec_states += [hs_dec, cs_dec]\n",
        "\n",
        "            dec_states_ips += curr_states_ips\n",
        "\n",
        "\n",
        "        dec_dense = model.get_layer('dense')\n",
        "\n",
        "        dec_ops = dec_dense(dec_ops)\n",
        "\n",
        "        dec_model = Model([dec_ips] + dec_states_ips, [dec_ops] + dec_states)\n",
        "\n",
        "        return enc_model,dec_model\n",
        "\n",
        "  def decode_sequence(self,enc_model,dec_model,input_seq):\n",
        "\n",
        "        # Encode the input as state vectors.\n",
        "        states_value = [enc_model.predict(input_seq)] * self.num_dec\n",
        "        \n",
        "        # Generate empty target sequence of length 1.\n",
        "        target_seq = np.zeros((1, 1))\n",
        "\n",
        "        # Populate the first character of target sequence with the start character.\n",
        "        target_seq[0, 0] = tgt_idx['B']\n",
        "\n",
        "        # Sampling loop for a batch of sequences\n",
        "        # (to simplify, here we assume a batch of size 1).\n",
        "        stop_condition = False\n",
        "        decoded_sentence = \"\"\n",
        "\n",
        "        while not stop_condition:\n",
        "\n",
        "            if self.cell == 'RNN' or self.cell == 'GRU':\n",
        "\n",
        "              dummy = dec_model.predict([target_seq] + [states_value])\n",
        "\n",
        "              output_tokens, states_value = dummy[0],dummy[1:]\n",
        "              \n",
        "            elif self.cell == 'LSTM':  \n",
        "\n",
        "              dummy = dec_model.predict([target_seq] + states_value)\n",
        "\n",
        "              output_tokens, states_value = dummy[0],dummy[1:]\n",
        "\n",
        "            if self.pred == 'greedy':\n",
        "\n",
        "              beam_w = 1\n",
        "            elif self.pred == 'beam_search':\n",
        "\n",
        "              beam_w = self.beam_width\n",
        "\n",
        "            sampled_token_index = self.beam_search_dec(output_tokens[0,:,:], beam_w)\n",
        "            sampled_token_index = sampled_token_index[beam_w-1][0]\n",
        "\n",
        "            # Sample a token\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "            sampled_char = rev_tgt_char_idx[sampled_token_index]\n",
        "\n",
        "            decoded_sentence += sampled_char\n",
        "\n",
        "            # Exit condition: either hit max length\n",
        "            # or find stop character.\n",
        "            if sampled_char == 'E' or len(decoded_sentence) > max_dec_seq_length:\n",
        "                stop_condition = True\n",
        "\n",
        "            # Update the target sequence (of length 1).\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "\n",
        "        return decoded_sentence\n",
        "  \n",
        "  def beam_search_dec(self,data, k):\n",
        "    \n",
        "        sequences = [[list(), 0.0]]\n",
        "        # walk over each step in sequence\n",
        "        for row in data:\n",
        "          all_candidates = list()\n",
        "          # expand each current candidate\n",
        "          for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "              candidate = [seq + [j], score - log(row[j])]\n",
        "              #candidate = [seq + [j], score - log1p(row[j])]\n",
        "              all_candidates.append(candidate)\n",
        "          # order all candidates by score\n",
        "          ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
        "          # select k best\n",
        "          sequences = ordered[:k]\n",
        "        return sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best Hyperparameters\n",
        "\n",
        "best_batch_size = 64\n",
        "best_beam_width = 3\n",
        "best_cell = 'LSTM'\n",
        "best_dec_search = 'beam_search'\n",
        "best_dropout = 0.2\n",
        "best_epochs = 10\n",
        "best_hidden_layer = 128\n",
        "best_ip_emb = 64\n",
        "best_learning_rate = 0.001\n",
        "best_num_dec = 3\n",
        "best_num_enc = 3"
      ],
      "metadata": {
        "id": "DuVa2ixx-fk3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = Seq_to_Seq(best_cell, ip_emb = best_ip_emb, hidden_layer=best_hidden_layer,\n",
        "                learning_rate= best_learning_rate, dropout=best_dropout,pred= best_dec_search,epochs = best_epochs,\n",
        "                batch_size = best_batch_size, beam_width = best_beam_width, num_enc =best_num_enc, num_dec = best_num_dec)\n",
        "  \n",
        "rnn_model.fit_model(enc_ip,dec_ip,dec_tgt,x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDygztxt_6km",
        "outputId": "8ef392e5-f550-4f1d-9b57-bf1d61cbce65"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Enc_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_emb (Embedding)            (None, None, 64)     1728        ['Enc_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_1 (LSTM)            [(None, None, 128),  98816       ['Enc_emb[0][0]']                \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " Dec_ips (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Enc_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_1[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_1[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_emb (Embedding)            (None, None, 128)    8448        ['Dec_ips[0][0]']                \n",
            "                                                                                                  \n",
            " Enc_hidden_3 (LSTM)            [(None, None, 128),  131584      ['Enc_hidden_2[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_2[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_2[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_1 (LSTM)            [(None, None, 128),  131584      ['Dec_emb[0][0]',                \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_2 (LSTM)            [(None, None, 128),  131584      ['Dec_hidden_1[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " Dec_hidden_3 (LSTM)            [(None, None, 128),  131584      ['Dec_hidden_2[0][0]',           \n",
            "                                 (None, 128),                     'Enc_hidden_3[0][1]',           \n",
            "                                 (None, 128)]                     'Enc_hidden_3[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 66)     8514        ['Dec_hidden_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 775,426\n",
            "Trainable params: 775,426\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 288s 379ms/step - loss: 0.9629 - accuracy: 0.3463\n",
            "Epoch 2/10\n",
            "691/691 [==============================] - 267s 386ms/step - loss: 0.6570 - accuracy: 0.5221\n",
            "Epoch 3/10\n",
            "691/691 [==============================] - 267s 386ms/step - loss: 0.4588 - accuracy: 0.6544\n",
            "Epoch 4/10\n",
            "691/691 [==============================] - 265s 384ms/step - loss: 0.3448 - accuracy: 0.7318\n",
            "Epoch 5/10\n",
            "691/691 [==============================] - 263s 381ms/step - loss: 0.2793 - accuracy: 0.7799\n",
            "Epoch 6/10\n",
            "691/691 [==============================] - 263s 380ms/step - loss: 0.2364 - accuracy: 0.8112\n",
            "Epoch 7/10\n",
            "691/691 [==============================] - 259s 375ms/step - loss: 0.2081 - accuracy: 0.8333\n",
            "Epoch 8/10\n",
            "691/691 [==============================] - 261s 378ms/step - loss: 0.1873 - accuracy: 0.8497\n",
            "Epoch 9/10\n",
            "691/691 [==============================] - 267s 386ms/step - loss: 0.1704 - accuracy: 0.8628\n",
            "Epoch 10/10\n",
            "691/691 [==============================] - 266s 385ms/step - loss: 0.1570 - accuracy: 0.8728\n",
            "0.3351843625055531\n"
          ]
        }
      ]
    }
  ]
}