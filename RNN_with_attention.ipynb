{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9ZhrUeTDsx-"
      },
      "outputs": [],
      "source": [
        "#Necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array,argmax,array_equal\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import models,Input\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, SimpleRNN, GRU,Lambda,Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.ticker as ticker\n",
        "tf.keras.backend.set_floatx('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xx30eIrpN9SX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbaf3771-bace-4857-963c-2d4fd3436044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 43.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install WandB\n",
        "\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "ryRqR9hHpoU0",
        "outputId": "80425916-a549-4555-90fb-2a6826c10c8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220515_113227-p9fgjekd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/p9fgjekd\" target=\"_blank\">prime-salad-263</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/p9fgjekd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f946fc2c890>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.init(project=\"CS6910_DL_Assignment_3\", entity=\"nomads\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dnebWKpu99",
        "outputId": "854e4789-d155-459f-b918-67eda29449d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 11:32:32--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.253.123.128, 142.250.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   223MB/s    in 7.9s    \n",
            "\n",
            "2022-05-15 11:32:40 (242 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Loading the dakshina dataset\n",
        "\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFMo0XNnqDq_",
        "outputId": "9a6afd9b-31c9-430d-83a5-8b581ce5f00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ]
        }
      ],
      "source": [
        "#Selecting the Hindi language\n",
        "\n",
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JkG0hgUAqER_"
      },
      "outputs": [],
      "source": [
        "#Directory for Training,Validation and Testing\n",
        "train_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n",
        "val_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n",
        "test_dir = \"./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PBzvL2e20Sx-"
      },
      "outputs": [],
      "source": [
        "# Reading the raw corpus\n",
        "#returns the native(Hindi) and romanized(English) versions of the words in the corpus\n",
        "\n",
        "import io\n",
        "def raw_corpus(crp):\n",
        "  Eng = []\n",
        "  Hindi= []\n",
        "  with io.open(crp, encoding ='utf-8') as f:\n",
        "    for line in f:\n",
        "      if '\\t' not in line:\n",
        "        continue\n",
        "      tokens = line.rstrip().split(\"\\t\")\n",
        "      Eng.append(tokens[1])\n",
        "      Hindi.append(tokens[0])\n",
        "  return Eng, Hindi "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K-VCpVH93sFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6b0ba2-1bda-4e8a-b574-50230eb9511b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples:  44204\n",
            "Validation examples:  4358\n",
            "Testing examples:  4502\n"
          ]
        }
      ],
      "source": [
        "train_src, train_tgt = raw_corpus(train_dir)\n",
        "val_src, val_tgt = raw_corpus(val_dir)\n",
        "test_src, test_tgt = raw_corpus(test_dir)\n",
        "\n",
        "print(\"Training examples: \", len(train_src))\n",
        "print(\"Validation examples: \", len(val_src))\n",
        "print(\"Testing examples: \", len(test_src))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BvnPFZvV4yKI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_u0pkPoq5GSq"
      },
      "outputs": [],
      "source": [
        "ip_txt_ns = []\n",
        "tgt_txt_ns = []\n",
        "val_ip_txt_ns = []\n",
        "val_tgt_txt_ns = []\n",
        "ip_char = set()\n",
        "tgt_char = set()\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(train_src, train_tgt):\n",
        "    # tab : \"start sequence\" character\n",
        "    # \\n  : \"end sequence\" character\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "    ip_txt_ns.append(txt_ip)\n",
        "    tgt_txt_ns.append(txt_tgt)\n",
        "\n",
        "    for char in txt_ip:\n",
        "        if char not in ip_char:\n",
        "            ip_char.add(char)\n",
        "\n",
        "    for char in txt_tgt:\n",
        "        if char not in tgt_char:\n",
        "            tgt_char.add(char)\n",
        "\n",
        "\n",
        "for (txt_ip, txt_tgt) in zip(val_src, val_tgt):\n",
        "    # tab : \"start sequence\" character\n",
        "    # \\n  : \"end sequence\" character\n",
        "    txt_tgt = \"B\" + txt_tgt + \"E\"\n",
        "    val_ip_txt_ns.append(txt_ip)\n",
        "    val_tgt_txt_ns.append(txt_tgt)\n",
        "    for char in txt_ip:\n",
        "        if char not in ip_char:\n",
        "            ip_char.add(char)\n",
        "    for char in txt_tgt:\n",
        "        if char not in tgt_char:\n",
        "            tgt_char.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YcpWebDU4o6_"
      },
      "outputs": [],
      "source": [
        "#Shuffling the Training and Validation dataset\n",
        "\n",
        "train_arr = np.arange(len(train_src))\n",
        "np.random.shuffle(train_arr)\n",
        "val_arr = np.arange(len(val_src))\n",
        "np.random.shuffle(val_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SD6j9o7H5U1g"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ips_txt = []\n",
        "tgts_txt = []\n",
        "\n",
        "for i in range(len(train_src)):\n",
        "    ips_txt.append(ip_txt_ns[train_arr[i]])\n",
        "    tgts_txt.append(tgt_txt_ns[train_arr[i]])\n",
        "\n",
        "val_ip_txt = []\n",
        "val_tgt_txt = []\n",
        "\n",
        "for i in range(len(val_src)):\n",
        "    val_ip_txt.append(val_ip_txt_ns[val_arr[i]])\n",
        "    val_tgt_txt.append(val_tgt_txt_ns[val_arr[i]])\n",
        "\n",
        "ip_char.add(\" \")\n",
        "tgt_char.add(\" \")\n",
        "\n",
        "ip_char = sorted(list(ip_char))\n",
        "tgt_char = sorted(list(tgt_char))\n",
        "\n",
        "enc_tokens = len(ip_char)\n",
        "dec_tokens= len(tgt_char)\n",
        "\n",
        "max_enc_seq_length = max([len(txt) for txt in ips_txt])\n",
        "max_dec_seq_length = max([len(txt) for txt in tgts_txt])\n",
        "\n",
        "val_max_enc_seq_length = max([len(txt) for txt in val_ip_txt])\n",
        "val_max_dec_seq_length = max([len(txt) for txt in val_tgt_txt])\n",
        "\n",
        "ip_tk_idx= dict([(j, k) for k, j in enumerate(ip_char)])\n",
        "tgt_tk_idx= dict([(j, k) for k, j in enumerate(tgt_char)])"
      ],
      "metadata": {
        "id": "5IslLeQE4K80"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKb2WqwM6rUS",
        "outputId": "b77065b4-3a70-4720-d1e0-1609a4649f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "{' ': 0, 'B': 1, 'E': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n"
          ]
        }
      ],
      "source": [
        "print(ip_tk_idx)\n",
        "print(tgt_tk_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CtAojV-O6p0G"
      },
      "outputs": [],
      "source": [
        "trc_ip_txt = ips_txt[:44000]\n",
        "trc_tgt_txt = tgts_txt[:44000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "31iEPN2D-UPA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fCZN_YHH-ZeJ"
      },
      "outputs": [],
      "source": [
        "ip_encd = np.zeros((len(trc_ip_txt), max_enc_seq_length, enc_tokens), dtype=\"float64\")\n",
        "\n",
        "tgt_decd = np.zeros((len(trc_ip_txt), max_dec_seq_length, dec_tokens), dtype=\"float64\")\n",
        "\n",
        "for i, (txt_ip, txt_tgt) in enumerate(zip(trc_ip_txt, trc_tgt_txt)):\n",
        "    for m, n in enumerate(txt_ip):\n",
        "        ip_encd[i, m, ip_tk_idx[n]] = 1.0\n",
        "    ip_encd[i, m + 1 :, ip_tk_idx[\" \"]] = 1.0\n",
        "    for m, n in enumerate(txt_tgt):\n",
        "        tgt_decd[i, m, tgt_tk_idx[n]] = 1.0\n",
        "    tgt_decd[i, m + 1 :, tgt_tk_idx[\" \"]] = 1.0\n",
        "\n",
        "val_ip_encd= np.zeros((len(val_ip_txt), max_enc_seq_length, enc_tokens), dtype=\"float64\")\n",
        "val_tgt_decd = np.zeros((len(val_tgt_txt), max_dec_seq_length, dec_tokens), dtype=\"float64\")\n",
        "\n",
        "for i, (txt_ip, txt_tgt) in enumerate(zip(val_ip_txt, val_tgt_txt)):\n",
        "    \n",
        "    for t, n in enumerate(txt_ip):\n",
        "        val_ip_encd[i, t, ip_tk_idx[n]] = 1.0\n",
        "    val_ip_encd[i, t + 1 :, ip_tk_idx[\" \"]] = 1.0\n",
        "\n",
        "    for t, n in enumerate(txt_tgt):\n",
        "        val_tgt_decd[i, t, tgt_tk_idx[n]] = 1.0\n",
        "    val_tgt_decd[i, t + 1: , tgt_tk_idx[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KWmlTIC8-dTu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KSyas_TA-gj1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N-RyyRhTQ2XC"
      },
      "outputs": [],
      "source": [
        "class Bahdanau(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(Bahdanau, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "    \n",
        "  def call(self, query, value):\n",
        "    \n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(value)))\n",
        "    \n",
        "    aw = tf.nn.softmax(score, axis=1)\n",
        "    vc = aw * value\n",
        "    vc = tf.reduce_sum(vc, axis=1)\n",
        "\n",
        "    return vc, aw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2mfk2-afoCeE"
      },
      "outputs": [],
      "source": [
        "class Seq_to_Seq_with_attention(object):\n",
        "\n",
        "  def __init__(self, cell = 'RNN', hidden_layer=32, learning_rate= 1e-3, drop_out = 0.3,\n",
        "               epochs = 10, batch_size = 32, attention = 'bahdanau'):\n",
        "    \n",
        "    self.cell = cell\n",
        "    self.hidden_layer = hidden_layer\n",
        "    self.learning_rate = learning_rate\n",
        "    self.drop_out = drop_out\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = attention\n",
        "\n",
        "  def fit_model(self, ip_encd, tgt_decd):\n",
        "\n",
        "    ip_encds = Input(shape=(max_enc_seq_length, enc_tokens), name='encoder_inputs')\n",
        "\n",
        "    if self.cell == 'LSTM':\n",
        "\n",
        "      enc_lstm = LSTM(self.hidden_layer,return_sequences=True, return_state=True, dropout = self.drop_out, name='encoder_lstm')\n",
        "      enc_ops, enc_hs, enc_cs = enc_lstm(ip_encds)\n",
        "      states_enc = [enc_hs, enc_cs]\n",
        "\n",
        "    elif self.cell == 'RNN':\n",
        "\n",
        "      enc_rnn = SimpleRNN(self.hidden_layer,return_sequences=True, return_state=True, dropout = self.drop_out, name='encoder_rnn')\n",
        "      enc_ops, enc_hs = enc_rnn(ip_encds)\n",
        "      states_enc = [enc_hs]\n",
        "\n",
        "    elif self.cell == 'GRU':\n",
        "\n",
        "      enc_gru = GRU(self.hidden_layer,return_sequences=True, return_state=True, dropout = self.drop_out, name='encoder_gru')\n",
        "      enc_ops, enc_hs = enc_gru(ip_encds)\n",
        "      states_enc = [enc_hs]\n",
        "\n",
        "    \n",
        "\n",
        "    # Attention Layer\n",
        "    if self.attention == 'bahdanau':\n",
        "      attention= Bahdanau(self.hidden_layer)\n",
        "\n",
        "    # Decoder Layers\n",
        "    inps_deco = Input(shape=(1, (dec_tokens + self.hidden_layer)),name='decoder_inputs')\n",
        "\n",
        "    if self.cell == 'LSTM':\n",
        "\n",
        "      dec_lstm = LSTM(self.hidden_layer, dropout = self.drop_out, return_state=True, name='decoder_lstm')\n",
        "    \n",
        "    elif self.cell == 'GRU':\n",
        "\n",
        "      dec_gru = GRU(self.hidden_layer, dropout = self.drop_out, return_state=True, name='decoder_gru')\n",
        "    \n",
        "    elif self.cell == 'RNN':\n",
        "\n",
        "      dec_rnn = SimpleRNN(self.hidden_layer, dropout = self.drop_out, return_state=True, name='decoder_rnn')  \n",
        "    \n",
        "    \n",
        "    dec_dense = Dense(dec_tokens, activation='softmax',  name='decoder_dense')\n",
        "    all_ops = []\n",
        "\n",
        "    ips = np.zeros((self.batch_size, 1, dec_tokens))\n",
        "    ips[:, 0, 0] = 1 \n",
        "\n",
        "    dec_ops = enc_hs\n",
        "    states = states_enc\n",
        "\n",
        "    for _ in range(max_dec_seq_length):\n",
        "\n",
        "      vc, aw = attention(dec_ops, enc_ops)\n",
        "      vc = tf.expand_dims(vc, 1)\n",
        "      \n",
        "      ips = tf.concat([vc, ips], axis=-1)\n",
        "\n",
        "      if self.cell == 'LSTM':\n",
        "\n",
        "        dec_ops, hs, cs = dec_lstm(ips, initial_state=states)\n",
        "\n",
        "      if self.cell == 'GRU':\n",
        "\n",
        "        dec_ops, hs = dec_gru(ips, initial_state=states)\n",
        "\n",
        "      if self.cell == 'RNN':\n",
        "\n",
        "        dec_ops, hs = dec_rnn(ips, initial_state=states)\n",
        "      \n",
        "      ops = dec_dense(dec_ops)\n",
        "      ops = tf.expand_dims(ops, 1)\n",
        "      all_ops.append(ops)\n",
        "      ips = ops\n",
        "      if self.cell == 'LSTM':\n",
        "\n",
        "        states = [hs, cs]\n",
        "\n",
        "      if self.cell == 'GRU' or self.cell == 'RNN':\n",
        "        \n",
        "        states = [hs]\n",
        "\n",
        "\n",
        "    dec_ops = Lambda(lambda x: K.concatenate(x, axis=1))(all_ops)\n",
        "    model = Model(ip_encds, dec_ops, name='model_encoder_decoder')\n",
        "    \n",
        "    optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(ip_encd, tgt_decd,\n",
        "              batch_size=self.batch_size, \n",
        "              epochs=self.epochs,\n",
        "              #callbacks = [WandbCallback()]\n",
        "              )\n",
        "\n",
        "    pred = model.predict(val_ip_encd[:4352], batch_size=self.batch_size)\n",
        "\n",
        "    total = 0\n",
        "    right = 0\n",
        "    v_t = 4352\n",
        "\n",
        "    for i in range(v_t):\n",
        "      \n",
        "      ohv = pred[i]\n",
        "      ohv1 = val_tgt_decd[i]\n",
        "      id2 = tf.argmax(ohv, axis=1)\n",
        "      id1 = tf.argmax(ohv1, axis=1)\n",
        "      \n",
        "      if (id2.numpy() == id1.numpy()).all():\n",
        "        right = right + 1\n",
        "        \n",
        "      total = total + 1\n",
        "      accuracy_epoch = right/total\n",
        "\n",
        "      if total % 50 == 0:\n",
        "        wandb.log({'epoch_accuracy' : accuracy_epoch})\n",
        "    \n",
        "    val_accuracy = right/total\n",
        "    \n",
        "    wandb.log({'val_accuracy' : val_accuracy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "y6v4kKgONH4q"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "\n",
        "        'drop_out': {\n",
        "            'values': [0.0, 0.1, 0.2]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [64, 128]\n",
        "        },\n",
        "        'hidden_layer':{\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'cell': {\n",
        "            'values': ['RNN', 'GRU', 'LSTM']\n",
        "        },\n",
        "        'attention': {\n",
        "            'values': ['bahdanau']    \n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC0C9Ol8QcW5",
        "outputId": "abcc7679-4a05-47ae-e1d7-b6ea42419cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: qnkre2iq\n",
            "Sweep URL: https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/qnkre2iq\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"nomads\", project=\"CS6910_DL_Assignment_3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5QeYGKXmlKHr"
      },
      "outputs": [],
      "source": [
        "def train_sweep():\n",
        "\n",
        "  config_defaults = {\n",
        "        'drop_out': 0.3,\n",
        "        'learning_rate': 1e-3,\n",
        "        'batch_size': 128,\n",
        "        'epochs' : 10,\n",
        "        'hidden_layer': 128,\n",
        "        'cell': 'LSTM',\n",
        "        'attention': 'bahdanau'\n",
        "        }\n",
        "\n",
        "  wandb.init(config = config_defaults)\n",
        "  \n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = str(config.cell)+ '_' + config.attention +'_bs_'+str(config.batch_size)\n",
        "  \n",
        "  rnn_model = Seq_to_Seq_with_attention(cell = config.cell, hidden_layer=config.hidden_layer, learning_rate= config.learning_rate, drop_out=config.drop_out,epochs = config.epochs, batch_size = config.batch_size, attention = config.attention)\n",
        "  \n",
        "  rnn_model.fit_model(ip_encd, tgt_decd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549,
          "referenced_widgets": [
            "ec379af07510413189cdd857e76e4c9c",
            "edb5759d1ecb4b668eab3271999e8093",
            "5bd2ffb4816e4dc5adbef82b8e8fe410",
            "06d6d80dd9fb436e8bb7b2ccbaf4f3dc",
            "dd28059028d3492abc10ad7f1b692727",
            "d7a8518901e1496683ac30af4748bd7e",
            "12ace75c1e5b4824a9f8556e2d451aff",
            "02c53181859147bfb59bcec7547fca01"
          ]
        },
        "id": "kzx3bHH1_1M3",
        "outputId": "5b961d63-a70a-448a-8425-b5b67b8e528f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4wfx2ypm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: bahdanau\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220515_113254-4wfx2ypm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/4wfx2ypm\" target=\"_blank\">scarlet-sweep-5</a></strong> to <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/tzlnj4ue\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/sweeps/tzlnj4ue</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "690/690 [==============================] - 243s 274ms/step - loss: 1.8560 - accuracy: 0.6399\n",
            "Epoch 2/2\n",
            "690/690 [==============================] - 150s 218ms/step - loss: 1.2139 - accuracy: 0.6911\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec379af07510413189cdd857e76e4c9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_accuracy</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>0.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">scarlet-sweep-5</strong>: <a href=\"https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/4wfx2ypm\" target=\"_blank\">https://wandb.ai/nomads/CS6910_DL_Assignment_3/runs/4wfx2ypm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220515_113254-4wfx2ypm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.agent(\"tzlnj4ue\", entity=\"nomads\", project=\"CS6910_DL_Assignment_3\", function =train_sweep, count=20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "RNN_with_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec379af07510413189cdd857e76e4c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edb5759d1ecb4b668eab3271999e8093",
              "IPY_MODEL_5bd2ffb4816e4dc5adbef82b8e8fe410"
            ],
            "layout": "IPY_MODEL_06d6d80dd9fb436e8bb7b2ccbaf4f3dc"
          }
        },
        "edb5759d1ecb4b668eab3271999e8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd28059028d3492abc10ad7f1b692727",
            "placeholder": "​",
            "style": "IPY_MODEL_d7a8518901e1496683ac30af4748bd7e",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5bd2ffb4816e4dc5adbef82b8e8fe410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ace75c1e5b4824a9f8556e2d451aff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02c53181859147bfb59bcec7547fca01",
            "value": 1
          }
        },
        "06d6d80dd9fb436e8bb7b2ccbaf4f3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd28059028d3492abc10ad7f1b692727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a8518901e1496683ac30af4748bd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12ace75c1e5b4824a9f8556e2d451aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c53181859147bfb59bcec7547fca01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}